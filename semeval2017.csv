,id,gold_keys,title,text_intro
0,S221267161400105X.txt,"['featur extract', 'classif', 'svm', 'scale-invari featur transform', 'microsoft kinect camera', 'classif method', 'speed up robust featur', 'comparison between two popular featur extract method', 'depth map', 'support vector machin', 'surf', 'sift']",.,"In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.
"
1,S0370269304009220.txt,"['harmon superspac', 'n=1/2 super-yang–mil theori with adjoint matter', 'transform canon under the deform supersymmetri', 'field redefinit', 'deform supersymmteri transform', 'singlet deform', 'n=1/2 super-yang–mil theori', 'r-symmetri group', 'antiholomorph scalar field', 'n=1/2 superspac', 'compon field', 'deform structur', 'gaug transform', 'su(2)r', 'singlet case', 'deform lagrangian', 'correct linear', 'the gaug and supersymmetri transform', 'singlet represent', 'singl function', 'n=2 supersymmetr u(1) gaug theori', 'deform paramet', 'deform supersymmetri', 'gaug and supersymmetri transform']",.,"There exist some interesting cases where the deformation structure becomes simple. One is the limit to the N=1/2 superspace [5], where the action should reduce to N=1/2 super-Yang–Mills theory with adjoint matter. Another interesting case is the singlet deformation [10,11], where the deformation parameters belongs to the singlet representation of the R-symmetry group SU(2)R. In this Letter, we will study N=2 supersymmetric U(1) gauge theory in the harmonic superspace with singlet deformation. In this case, the gauge and supersymmetry transformations get correction linear in the deformation parameter. Therefore we can easily perform the field redefinition such that the component fields transform canonically under the gauge transformation. In the case of N=1/2 super-Yang–Mills theory, such field redefinition is also possible [5]. But in this case the component fields do not transform canonically under the deformed supersymmtery transformation. In the singlet case, we will show that there is a field redefinition such that the redefined fields also transform canonically under the deformed supersymmetry. We will construct a deformed Lagrangian which is invariant under both the gauge and supersymmetry transformations. We find that the deformed Lagrangian is characterized by a single function of an antiholomorphic scalar field.
"
2,S2212667814001208.txt,"['hpc applic', 'small size hpc applic', 'parallel efﬁcienc', 'high perform and cloud comput', 'respons rate', 'scale up', ""amazon' hpc cloud"", 'hpc', 'hpc cluster', 'migrat them to cloud environ', 'high perform comput', 'speed up', 'execut of hpc applic in cloud', 'heterogen and dynam environ', 'ec2 cloud system', 'cloud', 'cloud environ', 'improv as well as evalu the perform', 'poor network perform', 'propos a new approach to improv the perform and scalabl of hpc applic', 'deploy on-demand']",.,"Improving as well as evaluating the performance of High Performance Computing (HPC) applications by migrating them to Cloud environments are widely considered as critical issues in the field of high performance and Cloud computing. However, poor network performance, heterogeneous and dynamic environments are some series of pitfalls for execution of HPC applications in Cloud. This paper proposes a new approach to improve the performance and scalability of HPC applications on Amazon's HPC Cloud. The evidence from our approach points a significant improvement in speed up and scale up with the response rate of more than 20 percent parallel efﬁciency on the Cloud in comparison to dedicated HPC cluster. We state that the EC2 Cloud system is a feasible platform for deploying on-demand, small sized HPC applications."
3,S0038092X14004824.txt,"['studi of the geometri of pyrheliomet', 'separ the measur of dni from that of the diffus irradi in the immedi vicin of the sun', 'improv the accuraci of pyrheliometr measur', 'includ estim of the circumsolar enhanc', 'and how that geometri interact with circumsolar radianc', 'pyrheliomet']",.,"Historically, the interest in accurate measurement of DNI started decades ago. Early studies (e.g., Linke, 1931; Linke and Ulmitz, 1940) identified the difficulty of separating the measurement of DNI from that of the diffuse irradiance in the immediate vicinity of the sun, hereafter referred to as circumsolar irradiance. Pastiels (1959) conducted a detailed study of the geometry of pyrheliometers, and how that geometry interacted with circumsolar radiance, using simplified representations of the latter. Various communications were then presented at a WMO Task Group meeting held in Belgium in 1966 (WMO, 1967) to improve the accuracy of pyrheliometric measurements, including estimates of the circumsolar enhancement. Ångström (1961) and Ångström and Rohde (1966) later contributed to the same topic, followed years later by Major (1973, 1980). The whole issue of instrument geometry vs. circumsolar irradiance was complex and confusing at the time because different makes and models of instruments had differing geometries. This was considerably simplified after WMO issued guidelines about the recommended geometry of pyrheliometers, which led to a relatively “standard” geometry used in all recent instruments. The experimental issues related to the measurement of DNI are discussed in Section 3.2.
"
4,S2212671612002375.txt,"['abstract and analyz the power grid secur investig procedur', 'ontology-bas power grid knowledg base', 'expert system', 'semant reason tool', 'power grid secur investig procedur', 'jena', 'specif applic of secur investig procedur ontolog and reason', 'introduc and analyz of semant reason tool', 'system', 'reason mechan', 'secur investig procedur ontolog and reason', 'knowledg share of knowledg base in expert system', 'knowledg base', 'ontolog technolog', 'power grid reason expert system', 'infer rule of grammar', 'associ relationship of procedur vocabulari']",.,"Power Grid reasoning expert system is a complex system. To solve knowledge sharing of knowledge Base in expert system, we abstract and analyze the power grid security investigation procedure by using ontology Technology. With ontology-based Power Grid knowledge base, we establish associated relationship of procedure vocabularies. In this paper, we introduce and analyze of semantic reasoning tools such as Jena. The reasoner mechanism and inference rules of grammar has been included and explained. At last we give a specific application of security investigation procedure ontology and reasoning."
5,S0370269304008780.txt,"['neutral 2sc matter', 'normal quark matter', 'quark phase', '2sc phase', 'cfl or normal quark matter core', 'njl model', 'stabl star', 'hybrid star', 'taylor expans', 'beta-equilibr electr', 'strang quark mass', 'hadron phase', 'color neutral quark matter', 'compact star', 'njl model studi', 'cfl phase']",.,"In the NJL model studied here, we find no stable stars with either CFL or normal quark matter cores. This is the opposite of the prediction of Ref. [15] where it was argued that there is no 2SC phase in compact stars. Let us be more precise: performing a Taylor expansion in the strange quark mass, the authors of Ref. [15] found that in beta-equilibrated electrically and color neutral quark matter the 2SC phase is always less favored than the CFL phase or normal quark matter. From this observation they concluded that the 2SC phase is absent in compact stars. In contrast to this result, it was shown in Ref. [16] in the framework of the NJL model that neutral 2SC matter could be the most favored quark phase in a certain regime. However, the authors argued that this interval might disappear if the hadronic phase is included more properly. This is indeed what we found for parameter set RKH, while for parameter set HK the 2SC phase survives only in a tiny window. Nevertheless, if Nature chooses to be similar to this equation of state, it will be this tiny window which gives rise to hybrid stars, whereas the CFL phase would be never present in compact stars.
"
6,S0010482516301810.txt,"['triangul surfac', '3d-dsa', 'cerebr angiographi', '3D visual', 'objet30 pro', 'vero', 'stl', 'dicom file', 'amira version X', 'smooth', 'triangular mesh', 'embol', '3D printer', 'remov spicule.', 'water', 'remesh', 'three-dimension digit subtract angiograph', '3D visual and measur softwar', '3D print model', 'measur', 'comput volumetr mesh', 'stl file', 'creat a 3D model of the target vessel segment', 'standard triangul languag', '3D model', 'immers in water', 'acryl resin']",.,"Three-dimensional digital subtraction angiographic (3D-DSA) images from diagnostic cerebral angiography were obtained at least one day prior to embolization in all patients. The raw data of 3D-DSA in a DICOM file were used for creating a 3D model of the target vessel segment. These data were converted to standard triangulation language (STL) surface data as an aggregation of fine triangular meshes using 3D visualization and measurement software (Amira version X, FEI, Burlington, MA, USA). An unstructured computational volumetric mesh was constructed from the triangulated surface. Smoothing and remeshing followed as next steps. The STL file was then transferred to a 3D printer (OBJET30 Pro; Stratasys Ltd., Eden Prairie, MN, USA). The resolution of the build layer was 0.028mm, and the 3D printed vessel model was produced using acrylic resin (Vero). Following immersion in water for a few hours, the surface of the 3D printed model was smoothed by manually removing spicule.
"
7,S0032386109006612.txt,"['hipco (high-pressur co) process', 'mwnt', 'chemic vapor deposit', 'cvd', 'cnt', 'the reaction of a gaseou carbon compound as feedstock', 'the most effect', 'the fulleren product method of laser ablat', 'the reaction of a gaseou carbon feedstock to form the nanotub on catalyst particl', 'synthes in the liquid phase', 'doe not use pre-form catalyst particl', 'swnt', 'observ in arc discharg fulleren reactor', 'produc through a varieti of synthesi techniqu', 'cvd techniqu', '“catalyt ga flow cvd”', 'polym', '“carpet” growth of carbon nanotub (cnts) from catalyst particl embed in a substrat', 'carbon nanotub', 'cheap', 'fluidiz bed', 'and scalabl cvd techniqu', 'metal catalyst particl', 'thi techniqu']",.,"In contrast with polymers, which are typically synthesized in the liquid phase, SWNTs are produced through a variety of synthesis techniques that typically involve the reaction of a gaseous carbon feedstock to form the nanotubes on catalyst particles. MWNTs were first observed in arc discharge fullerene reactors [1,26]; this technique was later adapted to produce SWNTs [3]. Similarly, the fullerene production method of laser ablation [27] was adapted to produce SWNTs (∼1.4nm diameter) in larger quantities on metal catalyst particles [28–30]. A number of chemical vapor deposition (CVD) processes have been developed to grow SWNTs and MWNTs, all involving the reaction of a gaseous carbon compound as feedstock. These processes include fluidized bed [31], “carpet” growth of carbon nanotubes (CNTs) from catalyst particles embedded in a substrate [32–35] as shown in Fig. 3, and “catalytic gas flow CVD” [36,37]. One of the most effective, cheap, and scalable CVD techniques is the HiPco (high-pressure CO) process, which does not use pre-formed catalyst particles unlike most other CVD techniques [38].
"
8,S2212667813001068.txt,"['permeabl', 'field exampl', 'sdr', 'poros', 'permeabl estim model', 'csm', 'nmr', 'schlumberg doll research', 'classif scale method', 'calibr', 'experiment measur', 'timur-co model', 'calibr the involv model paramet', 'sandston']",.,"It is difficult in directly predicting permeability from porosity in tight sandstones due to the poor relationship between core derived porosity and permeability that caused by the extreme heterogeneity. The classical SDR (Schlumberger Doll Research) and Timur-Coates models are all unusable because not enough core samples were drilled for lab NMR experimental measurements to calibrate the involved model parameters. Based on the classification scale method (CSM), after the target tight sandstones are classified into two types, the relationship between core porosity and permeability is established for every type of formations, and the corresponding permeability estimation models are established. Field examples show that the classification scale method is effective in estimating tight sandstone permeability."
9,S0045782514004812.txt,"['sn=defω×in', 'spatial domain Ω', 'space–tim slab', 'problem of dynam', 'hamiltonian descript', 'T)', 'variat format in the space–tim domain', 'coupl problem of consolid of geomateri', 's=defω×i', 'time domain i=(0', 'space–tim domain', 's=defω×i=s1∪s2⋯∪sn', 'first order time-deriv', 'rewritten in first-ord form']",.,"We shall establish the variational format in the space–time domain S=defΩ×I, for given spatial domain Ω and time domain I=(0,T), for a quite broad class of problems involving a first order time-derivative. In particular, the coupled problem of consolidation of geomaterials falls within this class. Another interesting application is the problem of dynamics, rewritten in first-order form, i.e. through a Hamiltonian description. It is of considerable interest to note from the outset that, due to the forward transport of information in time, it is always possible to consider a set of finite time intervals, whereby the solution at the end of any such interval will act as the initial data for the next one. To this end, we introduce a partition 0=t0<t1<⋯<tN=T of the considered time domain I=(0,T) into time-intervals In=(tn−1,tn) of length Δtn=tn−tn−1.11The abbreviated notation Δt=Δtn will be used henceforth for the current time step associated with In. Hence, we define space–time slabs Sn=defΩ×In such that the space–time domain can be given as S=defΩ×I=S1∪S2⋯∪Sn.
"
10,S0167273813005298.txt,"['“bulges”', 'oxide-ion diffus', 'present materi', 'oxid', 'cation', 'Ta and Re cation', 'anion', 'fluorit materi', 'ion']",.,"At 200 – 300°C: nuclear densities are localised in the tetrahedral volume roughly covering the 8c and 32f positions with “bulges” of nuclear densities pointing toward the 48i position, while at 400 and 500°C continuous nuclear densities forming a straight line along the <100> direction are found, indicative of oxide-ion diffusion pathway along that direction. In the literature, curved pathways along the <100> direction passing through the 48i site are generally observed in fluorite materials [20], the prevalence of curve pathway as opposed from straight pathway is explained by the repulsion between cation and anions, the curved pathway allowing the cation–anion to maintain a reasonable distance. However, a straight pathway is observed for Y0.785Ta0.215O1.715 [23], as is the case for the present material. This suggests that Ta and Re cations might play a similar role in these systems.
"
11,S0375960113006725.txt,"['ch3oh', 'maser hydroxyl molecul', 'hydrogen line', 'emiss mechan', 'cosmic maser radio sourc', 'radio-mas', 'OH', 'light laser', 'observ', 'h2o', 'methanol maser', 'neutron star', 'optic laser', 'maser cluster', 'OH line', 'radiat dilut coeffici']",.,"Observations show that in the same area with dimensions of a few tenths of a parsec could be many sources, some of which only emits OH lines, and some – only lines H2O. The only known in physics the emission mechanism that can give tremendous power within a narrow range of the spectrum, is coherent (i.e. the same phase and direction) light lasers, which are called optical lasers, and radio-masers. Cosmic maser radio sources emitting in the lines of the molecules have an extremely high brightness temperature radiation Tb. In the molecules of methanol masers (CH3OH) Tb value can reach 109 K, with masers hydroxyl molecules (OH) 6×1012 K. The typical size of the maser clusters is about 1014–1015 m and the neutron star radius is of the order of 10 km. Thus, the radiation dilution coefficient is equaled approximately (2.5×10−23)–(2.5×10−21) and, therefore, μB2B2/4(hν)2∼(2.4×10−5)–(2.4×10−7) for the hydrogen line 21 cm and of the order 10−5–10−7 for the OH 18 cm line or the same order as Eq. (1).
"
12,S1361841516300342.txt,"['cost function', 'kalman filter', 'probabilist and stochast approach', 'evolutionari algorithm', 'search for local and global optima', 'estim a cost function gradien', 'genet algorithm optim', 'condens form of sequenti mont carlo sampl', 'genet popul']",.,"Probabilistic and stochastic approaches can facilitate the search for local and global optima. Evolutionary algorithms, such as genetic population (Jomier et al., 2006; Rivest-Henault et al., 2012; Ruijters et al., 2009), are considered as a strategy that is “less likely to get stuck in a local optimum” (Ruijters et al., 2009). A cost function consisting of the “sum of the Gaussian-blurred intensity values in the [DSA] at the projected model points” (Jomier et al., 2006) is optimized using a genetic algorithm optimizer. Other authors “use the Condensation form of sequential Monte Carlo sampling to estimate a cost function gradient” (Florin et al., 2005) for finding the global minimum. Besides, the Kalman filter is successfully adopted (Curwen et al., 1994; Feldmar et al., 1997; Toledo et al., 1998).
"
13,S0003491615000433.txt,"['quantum mechan featur', 'nuclear theori', 'imag techniqu', 'simpl metal', 'laser', 'c60', 'semi classic treatment of dynam correl', 'field of cluster and nano structur', 'improv molecular dynam method', 'combin quantum featur', 'nuclear reaction', 'thermal', 'quantum liquid', 'semi-class method', 'qualit describ dynam processes.', 'veri intens laser puls', 'simpl metal with suffici deloc wave function', 'quantum approach', 'organ system', 'quantum shell effect']",.,"Nuclear theory devoted major efforts since 4 decades to describe thermalization in nuclear reactions, predominantly using semi-classical methods  [13,14,10], in line with similar problems in quantum liquids  [15,16]. There were attempts to develop improved molecular dynamics methods combining quantum features with a semi classical treatment of dynamical correlations  [17,18]. Still, no clear-cut quantum approach is readily available yet, in spite of numerous formal attempts [19,20,10]. The field of clusters and nano structures is far younger but fast developing in relation to the ongoing developments of lasers and imaging techniques. Semiclassical approaches were also considered in the field to include some dynamical corrections  [21,22] and could qualitatively describe dynamical processes. But such approaches are bound to simple metals with sufficiently delocalized wave functions, and thus smooth potentials justifying semiclassical approximations. The case of organic systems, in particular the much celebrated C60   [4,23], cannot be treated this way. Semi classical, and even classical approaches, can be used at very high excitations such as delivered by very intense laser pulses  [2]. In such cases the system is blown up and details of its quantum mechanical features do not matter anymore. But for less violent scenarios, quantum shell effects cannot be ignored.
"
14,S2212667812000032.txt,"['solv the cross-cut concern', 'model to test aspect-ori softwar', 'autom select test case', 'algorithm of select aspect relev test case', 'develop a new tool to implement the theoret of autom select test case', 'aop', 'test model', 'bank account system', 'aspect-ori program']",.,"Aspect-oriented Programming (AOP) can well solve the cross-cutting concerns. Because of the different features of aspect, AOP requires new techniques for testing. First, this paper proposes a model to test aspect-oriented software. In order to support the testing model of the first three steps, we propose the algorithm of selecting aspect relevant test cases. Then, we develop a new tool to implement the theoretical of automating select test case. Finally, a case of the Bank Account System is studied to illustrate our testing approach."
15,S0029549314001551.txt,"['enlarg sodium plenum', 'sodium plenum', 'core region', 'reactiv reduct', 'reduc the upper axial reflector width', 'increas in the sub-assembl length', 'design solut', 'core', 'reduc neutron backscatt from the reflector region abov the plenum', 'plenum', 'neutron leakag', 'modif in the core geometri', ""increas of the layer' thick"", 'neutron', 'absorb layer', 'axial reflector', 'core design modif that optimis the total sodium void reactiv', 'absorb and boron layer', 'pan-cak geometri of the activ core region', 'boron layer', 'reduc neutron backscatt', 'upper plenum', 'sodium']",.,"An increase of neutron leakage from the core region can be achieved through modifications in the core geometry (usually by adopting a pan-cake geometry of the active core region at the expense of the general neutron economy). Extensive studies determined a set of core design modifications that optimised the total sodium void reactivity (becoming less positive). Among the most efficient design solutions identified is an enlarged sodium plenum above the active core region in combination with an absorber layer above the sodium plenum (to reduce neutron backscattering from the reflector region above the plenum). Fig. 19 shows the combined effect of different upper plenum thicknesses of the absorber and boron layers. It can be observed that the sequential increase of the layer's thickness converge to an asymptotic value of reactivity reduction slightly over 800pcm. The pair of values selected was 60cm for the sodium plenum and 30cm for the boron layer. These modifications implied a considerable increase in the sub-assembly length that was compensated by reducing the upper axial reflector width (Sun et al., 2013).
"
16,S0039602899010493.txt,"['surfac oxygen ion', 'surfac defect', 'crystal code', 'AD transit', 'densiti of state', 'do', 'densiti function theori', 'hartree–fock method', 'mie', 'dft', 'mie spectra', 'AD', 'cetep code', 'adsorb speci', 'auger de-excit']",.,"Although the basic mechanisms of the AD process are reasonably well understood, it has not proved simple to apply existing theories to the interpretation of experimental data. What is needed is a combination of the AD theory and the electronic structure of realistic systems, including surface defects and adsorbed species. Such electronic structure calculations are still complex and time-consuming. In many cases, especially for insulating surfaces, attempts to model MIES spectra use simple or intuitive models. In Refs. [4,6,23] it is assumed that the main transition mechanism is Auger de-excitation, and the MIES spectra have been simulated by the surface density of states (DOS) projected on the surface oxygen ions of the uppermost surface layer using a Hartree–Fock method (the crystal code [24,25]) and a density functional theory (DFT) method (the cetep code [26]). The effect of the overlap between the surface and He(1s) wavefunctions was taken into account only approximately by applying an additional z-dependent exponential factor to the surface DOS. Other workers [5,6] estimated the AD transition probability using a DOS projected on to the projectile 1s atomic orbital. However, they were not able to use state-of-the-art methods for the surface electronic structure. Yet the success of the simplified treatments [4–6], especially for MIES features such as relative energies of the different peaks, suggests that real spectra are indeed related to the projection of the surface DOS on to the projectile orbital.
"
17,S1875952116300209.txt,"['review of avail databas collect', 'english speak particip', 'emdb', 'film stim databas', 'review', 'test whether haptic pattern can convey or enhanc the mood music', 'film stim', 'databas collect', 'emot movi databas', 'affect movi clip corpu', 'film stim select', 'enhanc the mood']",.,"In order to test whether haptic patterns can convey or enhance the mood music of a movie, an affective movie clip corpus was required consisting of clips labeled according to the emotion conveyed in the mood music. The following database collections were examined as possible sources for the corpus: the Emotional Movie Database (EMDB) [19], and Film Stim [20]. However, these were discarded after review as unsuitable. The aim of this study is to enhance the mood in the film score, and in the case of the clips in the EMDB, no audio is provided which deemed the clips unsuitable. In the case of the Film Stim database, the clips are in French rather than English, and with no subtitles which where also deemed unsuitable since the studies are carried out with English speaking participants. Furthermore, the Film Stim selection is based on the affective content of the narrative as in most of them there is no music which is also unsuitable as discussed. From our review of available database collections, it was found that at present there is no standard corpus of affective movie clips where the affective indexing referred to the musical score of the clip.
"
18,S0968432814000250.txt,"['deposit of heavi metal', 'imag', 'low beam energi', 'visualis of structur', 'scan electron microscopi', 'interact volum', 'membran', 'synapt vesicl', 'tem', 'transmiss', 'enhanc axial resolut', 'tradit manual techniqu', 'sampl prepar', 'latest system', 'electron imag', 'volum EM', 'high effici electron detector', 'transmiss electron microscopi', 'cell biolog studi', 'transmiss and scan em', 'membran bilay', 'volum imag', 'scan electron microscopi (sem) technolog', 'field emiss electron sourc', 'heavi metal', 'ultrastructur examin of biomed specimen', 'resolv individu leaflet of membran bilay', 'sem', 'scan electron microscop']",.,"Volume EM can be performed using transmission or scanning electron microscopes. Each approach has its own strengths and weaknesses, and the choice is dependant on the required lateral (x, y) and axial (z) resolution, and the size of the structure of interest. Historically, transmission electron microscopy (TEM) was the tool of choice for ultrastructural examination of biomedical specimens at sub-nanometer resolution. However, for many cell biology studies structural resolution is actually limited by the deposition of heavy metals onto membranes during sample preparation. In addition, voxel dimensions may only need to be half that of the smallest expected feature of interest (Briggman and Bock, 2012). Advances in scanning electron microscopy (SEM) technology are now driving a paradigm shift in electron imaging. SEMs with field emission electron sources and high efficiency electron detectors can achieve lateral resolutions in the order of 3nm, allowing visualisation of structures such as synaptic vesicles and membranes (De Winter et al., 2009; Knott et al., 2008; Vihinen et al., 2013; Villinger et al., 2012), though resolving individual leaflets of membrane bilayers remains a challenge (Vihinen et al., 2013). The use of low beam energies also limits the interaction volume, enhancing axial resolution (Hennig and Denk, 2007). In this review, volume imaging in both transmission and scanning EMs will be explored, moving from traditional manual techniques, through to the latest systems where aspects of both sample preparation and imaging have been automated.
"
19,S0165212511000874.txt,"['multipl scale approach', 'higher frequenc', 'multiple-scal analysi', 'duct', 'sound propag', 'acoust frequenc', 'numer method', 'finite-el method', 'strongli curv duct', 'mean flow', 'uniform mean flow', 'calcul the eigenmod', 'mean swirl flow', 'multiple-scal approach', 'propag of unsteadi disturb', 'straight parallel duct', 'aeroengin configur', 'aeroengin']",.,"The propagation of unsteady disturbances in ducts of slowly-varying geometry, such as those typical of an aeroengine, can be successfully modelled using a multiple scales approach. From the first application [1] of multiple-scales analysis to sound propagation in ducts of rectangular and circular cross section without mean flow, more recent developments have extended the method to cases with uniform mean flow [2], mean swirling flow [3], ducts of arbitrary cross section [4] (with uniform mean flow) and strongly curved ducts [5]. The multiple-scales approach has a number of distinct advantages over full numerical methods as it is ideally suited to handle higher frequencies and the computational complexity is only marginally more than calculating the eigenmodes inside a straight parallel duct. The accuracy and usefulness of the multiple scales approach has been validated against finite-element methods [6] for realistic aeroengine configurations and acoustic frequencies [7,8].
"
20,S0010938X15301554.txt,"['corros', 'aerospac applic', 'compositionally-distinct phase', 'copper-contain second phase particl', 'S phase', 'alloy matrix', 'enrich', 'particl', 'dealloy particl', 'surfac treatment', 'cathod site', 'alloy', 'corros resist', 'thermomechan process', 'copper', 'corros behaviour', 'second phase particl', 'S phase particl', 'al2cumg', 'AA 2024-t3 aluminium alloy', 'dealloy', 'aa2024 alloy', 'decreas of the volta potenti', 'alloy element', 'magnesium', 'constitu particl', 'intermetal particl']",.,"AA 2024-T3 aluminium alloy is widely used for aerospace applications due to its high strength to weight ratio and high damage tolerance that result from copper and magnesium as the principal alloying elements and appropriate thermomechanical processing. The microstructure of the alloy is relatively complex and a number of compositionally-distinct phases have been identified [1]. Although possessing favourable mechanical properties, the alloy is relatively susceptible to corrosion and generally requires surface treatment in practical applications. The corrosion behaviour of the alloy is particularly affected by the presence of the intermetallic particles due to their differing potentials with respect to the alloy matrix [2–9]. Copper-containing second phase particles at the alloy surface are particularly detrimental to the corrosion resistance as they provide preferential cathodic sites [2,10]. One of the principle types of second phase particle that is important to the corrosion behaviour of the alloy is the S phase (Al2CuMg) particle [1,11]. Dealloying of S phase particles, which may account for ∼60% of the constituent particles in AA2024 alloys [11], is commonly observed when the alloy is exposed to an aggressive environment. The particles are considered as important initiation sites for severe localized corrosion in the alloy [11–22]. The dealloying of the S phase particles and the resulting enrichment of copper result in a decrease of the Volta potential with respect to the matrix and hence the dealloyed particles become active cathodic sites [23–25].
"
21,S0370269304007439.txt,"['fix by the experiment yield on (multi-)strang baryon', 'pomeron', 'self-consist quantum mechan multipl scatter formal', 'projectil and target nucleon', 'the format of the θ+-baryon', '“semihard pomeron”', 'elementari interact', 'q–qq', 'mont carlo program', 'nucleon remnant', 'Θ+ baryon', 'phenomenolog soft pomeron exchang', 'leg parton', 'parton-bas gribov–regg theori', 'spectat parton', 'q̄–q̄q̄', 'high energi hadron and nuclear collis', 'nexu 3.97', 'piec of the qcd parton ladder sandwich between two soft pomeron which are connect to the projectil and to the target in the usual way', 'pomeron emiss', '(multi-)strang baryon', 'q–q̄', '(soft) parton ladder', 'color singlet', 'perturb (high pt) parton', 'microscop (predominantli soft) parton cascad']",.,"In contrast to the H particle, the situation for the Θ+ baryon is very promising. Thus, in this Letter we explore the formation of the Θ+-baryon within a new approach called parton-based Gribov–Regge theory. It is realized in the Monte Carlo program NEXUS 3.97 [22,23]. In this model high energy hadronic and nuclear collisions are treated within a self-consistent quantum mechanical multiple scattering formalism. Elementary interactions, happening in parallel, correspond to underlying microscopic (predominantly soft) parton cascades and are described effectively as phenomenological soft pomeron exchanges. A pomeron can be seen as layers of a (soft) parton ladder, which is attached to projectile and target nucleons via leg partons. At high energies one accounts also for the contribution of perturbative (high pt) partons described by a so-called “semihard pomeron”—a piece of the QCD parton ladder sandwiched between two soft pomerons which are connected to the projectile and to the target in the usual way. The spectator partons of both projectile and target nucleons, left after pomeron emissions, form nucleon remnants. The legs of the pomerons form color singlets, such as q–q̄, q–qq or q̄–q̄q̄. The probability of q–qq and q̄–q̄q̄ is controlled by the parameter Pqq and is fixed by the experimental yields on (multi-)strange baryons [23].
"
22,S0370269304009013.txt,"['isospin', 'pp-collis', 'measur the spin–spin correl paramet', 'reaction', 'fermion', 'the hyperon Y', 'binari reaction', 'gener theorem', 'total angular momentum', 'determin of the p-pariti', 'particl', 'model independ method', 'nucleon', 'polar transfer', 'conserv of the p-pariti', 'photoproduct', 'thi reaction', 'determin the pariti']",.,"Several methods based on dynamical assumptions were suggested for determination of the P-parity of the Θ+ [13]. According to a general theorem [14], in order to determine the parity of one particle in a binary reaction one has to know polarizations at least of two fermions participating in this reaction. Model independent methods for determination of the P-parity of the Θ+ were suggested recently in Refs. [15,16] for pp-collision, and in Ref. [17] for photoproduction of the Θ+. The method of Refs. [15,16], based on the assumption that the spin of the Θ+ equals 12, suggests to measure the spin–spin correlation parameter in the reaction p→p→→Σ+Θ+ near the threshold. We generalize here this method for an arbitrary spin of the Θ+ and both isospins T=0 and T=1 of the NN channel of the NN→YΘ+ reaction. Furthermore, we consider a polarization transfer from a nucleon to the hyperon Y in this reaction. Our consideration is model independent, since it is based only on conservation of the P-parity, total angular momentum and isospin in the reaction and the generalized Pauli principle for nucleons.
"
23,S2212667814000331.txt,"['failur fuel pressur characterist were analyz', 'PT pump work principl wa analyz', 'analysi', 'diesel engin PT fuel', 'PT pump', 'portabl signal acquisit and analysi system', 'detect the diesel engin PT fuel system state', 'diesel engin PT fuel system', 'analysi system', 'diagnos the diesel engin PT fuel system', 'problem that the diesel engin PT fuel system is unabl to field maintain', 'diesel engin PT pump', 'signal acquisit']",.,"In order to solve the problem that the diesel engine PT fuel system is unable to field maintain, developed a portable signal acquisition and analysis system for diesel engine PT fuel system. Firstly, the PT pump work Principle was analyzed, and the PT pump failure mapping relation between reason and failure phenomenon was analyzed; Secondly, the diesel engine PT pump failure fuel pressure characteristics were analyzed; Lastly, using the portable signal acquisition and analysis system to diagnose the diesel engine PT fuel system, experiment results show that the system can correctly detect the diesel engine PT fuel system state."
24,S0370269304009293.txt,"['qcd potenti', 'multipol expans', 'hard cutoff scheme', 'vqcd(r)', 'ope', 'dimension regular']",.,"An OPE of VQCD(r) was developed in [3]. In this and the next paragraph, we review the content of that paper relevant to our analysis. Within this framework, short-distance contributions are contained in the potentials, which are in fact the Wilson coefficients, while non-perturbative contributions are contained in the matrix elements that are organized in multipole expansion in r→ at r≪ΛQCD−1. The following relation was derived: (16)VQCD(r)=VS(r)+δEUS(r),(17)δEUS=−ig2TFNC∫0∞dte−iΔV(r)t×〈r→⋅E→a(t)φadj(t,0)abr→⋅E→b(0)〉+O(r3). VS(r) denotes the singlet potential. δEUS(r) denotes the non-perturbative contribution to the QCD potential, which starts at O(ΛQCD3r2) in the multipole expansion. ΔV(r)=VO(r)−VS(r) denotes the difference between the octet and singlet potentials; see [3] for details. Intuitively VS(r) corresponds to VUV(r;μf) and δEUS(r) to VIR(r;μf). We adopt dimensional regularization in our analysis; we also refer to hard cutoff schemes when discussing conceptual aspects.
"
25,S0010938X15002954.txt,"['measur the kinet of 2D pit propag', 'semi-quantit model', '2D pit', 'current', 'ni–f [35] thin film', 'anod current', '2D disk', '1D pencil electrod', '2D pit propag', 'Al alloy', 'laci pit cover', 'pit edg', 'Al', 'pit', 'fe-co thin film', 'pit growth', 'stainless steel thin film', 'laci pit cover format', 'video imag', 'pit propag']",.,"There have been relatively few attempts to observe and in some cases extract the average current density from video images taken of growing 2D pits. Frankel presented a method to directly measure the average anodic current density from the growing pit boundary velocity in Al [33], an Al alloy [34] and Ni–Fe [35] thin films. Subsequently, Ryan et al. [27,36] determined the anodic current density in pits propagating as 2D disks in stainless steel thin films by measuring the pit edge movement velocity. Ernst and Newman [11,12,37] studied stability of pit growth in detail and measured the kinetics of 2D pit propagation in depth and width and compared the results with kinetics in 1D pencil electrodes. They developed a semi-quantitative model for pit propagation which explained the lacy pit cover formation during the pit growth, although they did not measure current density within the pit. More recently, Tang and Davenport [38] tracked the pit boundary movement and computed the instantaneous but average current density in Fe-Co thin films. However, there have been no previous attempts to quantify the local current density during inhomogeneous growth of pits, although such local variation in current density has long been recognised [7].
"
26,S0370269304006161.txt,"['fermi and gamow–tel transit strength', 'shell model', 'shell model for fermi and gamow–tel transit', 'crpa', 'the fermi and gamow–tel transit', 'mema', 'ia', 'nuclear absorpt cross section for the charg current neutrino reaction', '4.38\xa0mev in 40k', 'absorpt event through the charg current reaction', 'isobar analogu state', 'continuum random phase approxim', 'electron', 'the absorpt cross section', 'predict e−(e+) event rate', 'calcul by martinez-pinedo et al.', 'treatment of the coulomb distort', 'nuclear model depend', 'supernova neutrino energi', 'coulomb effect', 'modifi effect momentum approxim', 'neutrino absorpt cross section', 'residu nucleu', 'positron']",.,"Absorption events through the charged current reactions (2)νe+40Ar→e−+40K∗andν̄e+40Ar→e++40Cl∗. There is some uncertainty in predicting e−(e+) event rates for these processes which arise due to the nuclear model dependencies of the absorption cross section and the treatment of the Coulomb distortion of electron (positron) in the field of the residual nucleus. The nuclear absorption cross section for the charged current neutrino reactions in 40Ar relevant to supernova neutrino energies was first calculated by Raghavan [10] and Bahcall et al. [11] for Fermi transitions leading to isobaric analogue state (IAS) at 4.38 MeV in 40K∗. Later Ormand et al. [12] used a shell model to calculate the Fermi and Gamow–Teller transitions. In these calculations Fermi function F(Z,Ee) was used to take into account the Coulomb effects. In a recent paper Bueno et al. [13] make use of a calculation by Martinez-Pinedo et al. [14] who use a shell model for Fermi and Gamow–Teller transitions and a continuum random phase approximation (CRPA) for forbidden transitions to calculate the absorption cross sections. In this calculation the Coulomb distortion of the produced electron is treated with a hybrid model where a Fermi function is used for lower electron energies and modified effective momentum approximation (MEMA) for higher electron energies [14–17]. In a recent work Bhattacharya et al. [18] have measured the Fermi and Gamow–Teller transition strengths leading to excited states up to 6 MeV in 40K∗ and obtained the neutrino absorption cross section for supernova neutrinos in 40Ar.
"
27,S0021999115003423.txt,"['raw imag data set', 'imag data set', 'cell track problem', 'segment', 'multi-cel imag data set', 'problem of cell track', 'geometr evolut law model', 'algorithm', 'mathemat model', 'pde constrain optimis problem', 'theoret and comput framework', 'experiment imag data set', 'introduc our approach to cell track', 'our model', 'phase field framework']",.,"The remainder of our discussion proceeds as follows. In Section 2 we briefly describe the problem of cell tracking and introduce our approach to cell tracking, which may be regarded as fitting a mathematical model to experimental image data sets. We present the geometric evolution law model we seek to fit, which is a simplification of recently developed models in the literature that show good agreement with experiments [8,10–12,4,13,9]. We finish Section 2 by reformulating our model into the phase field framework, which appears more suitable for the problem in hand, and we formulate the cell tracking problem as a PDE constrained optimisation problem. In Section 3 we propose an algorithm for the resolution of the PDE constrained optimisation problem and we discuss some practical aspects related to the implementation. In particular we note that the theoretical and computational framework may be applied directly to multi-cell image data sets and raw image data sets (of sufficient quality) without segmentation. In Section 4 we present some numerical examples for the case of 2d single and multi-cell image data sets. Finally in Section 5 we present some conclusions of our study and discuss future extensions and applications of the work.
"
28,S0011227515000648.txt,"['lnt', '110-nm process technolog', 'long eras', 'process technolog', 'threshold slope', 'batch #3/#4', 'assembl line', 'eras and program timeout', 'product chang', 'transconductance/gain', 'transistor paramet', 'program time', 'batch #1/#2', '#5/#6', 'pass rate', 'bit error', 'threshold voltag', 'toler']",.,"The product change between batches #1/#2 and the others is the most influential on the test results. The redesign and upgrade to 110-nm process technology reduces the pass rate at LNT by approximately half. This is mainly caused by the increased incidence of erase and program timeouts with some contribution from long erase and program times and bit errors. The difference in pass rates at 88K between batches #3/#4 and #5/#6, which use the same process technology with the same dimensions, can be explained by the fabrication in different assembly lines, where other processes or base materials may have been changed. This means different tolerances in base materials and production process, which are more pronounced the lower the temperature. Some of the differences of technology scale may reflect shifts in transistor parameters such as transconductance/gain, threshold voltage, and threshold slope [7].
"
29,S0010938X13005945.txt,"['surfac rough of the coat wa evalu', 'adhesion/cohes', 'scratch test method', 'outer layer', 'scratch indent were carri out', 'eight measur', 'determin of locat of spallation/delamin', 'understand the natur of the coat failur', 'surfac rough tester', 'revetest system (csm instrument SA', 'rough', 'load forc and penetr depth were record', 'load forc and penetr depth were record and their respect valu were correl with the observ failur locat', 'Ra', 'switzerland) equip with a h-270 diamond indentor (200μm diameter)', 'adhesion/cohes of the coat', 'coat']",.,"The adhesion/cohesion of the coating was evaluated by the scratch test method, using a Revetest system (CSM Instruments SA, Switzerland) equipped with a H-270 diamond indentor (200μm diameter). Six scratch indentations were carried out under previously optimized conditions (linear progressive load mode 1–4N, 4Nmin−1). In order to aid in determination of location of spallation/delamination, an extended scratch length of 6mm was employed. The scratch tracks were subsequently observed by SEM to determine the locations of the first coating failure and to understand the nature of the coating failure. During the scratch tests, the loading force and penetration depth were recorded and their respective values were correlated with the observed failure locations. The surface roughness of the coating was evaluated using a surface roughness tester (TR200, Timegroup Inc.) according to ISO standard [29]. Due to the presence of the open porosity in the outer layer of the coating, a measurement length for determination of the roughness (Ra) of 0.8mm was used. In total, eight measurements were carried out in different directions.
"
30,S2212667814001361.txt,"['nsga-ii algorithm', 'cost', 'qualiti', 'optim problem', '(time', 'quantifi the qualiti obtain for a ga well drill project', 'contractor select problem', 'object', 'un-experienc manag', 'ga well drill project', 'project manag', 'sensit analysi', 'learnabl properti', 'determin the project time and cost', 'project time and cost', 'contractor select']",.,"Contractor selection for a project is an important decision, one for the project time and cost, next for the quality obtained by the project. Although the project managers can easily determine the project time and cost, the quality is usually undefined especially for un-experienced managers. With a learnable property, an approach is first introduced in this paper to quantify the quality obtained for a gas well drilling project. Then, based on these three objectives (time, cost, and quality), a contractor selection problem is converted to an optimization problem. Next, the NSGA-II algorithm is utilized for solution. At the end, a sensitivity analysis is performed to select the parameters of the algorithm."
31,S0079642515000705.txt,"['vapor particl', 'analyt model', 'deposit flux', 'geometr featur', 'geometr consider', 'thin film', 'atom', 'singl angular direct', 'surfac shadow mechan', 'continuum approach', 'analyt semi-empir model', 'film surfac', 'predict of the relat between the incid angl of the deposit flux and the tilt angl of the column', 'analyz the growth mechan', 'groov seed substrat', 'nanocolumn', 'quantit describ the aggreg of columnar structur', 'film', 'surfac diffus', 'geometr factor', 'aggreg of vapor particl onto a surfac']",.,"When dominated by surface shadowing mechanisms, the aggregation of vapor particles onto a surface is a complex, non-local phenomenon. In the literature, there have been many attempts to analyze the growth mechanism by means of pure geometrical considerations; i.e., by assuming that vapor particles arrive at the film surface along a single angular direction [38,41]. Continuum approaches, which are based on the fact that the geometrical features of the film (i.e., the nanocolumns) are much larger than the typical size of an atom [42,266,267], have been also explored. For instance, Poxson et al. [228] developed an analytic model that takes into account geometrical factors as well as surface diffusion. This model accurately predicted the porosity and deposition rate of thin films using a single input parameter related to the cross-sectional area of the nanocolumns, the volume of material and the thickness of the film. Moreover, in Ref. [39], an analytical semi-empirical model was presented to quantitatively describe the aggregation of columnar structures by means of a single parameter dubbed the fan angle. This material-dependent quantity can be experimentally obtained by performing deposition at normal incidence on an imprinted groove seeded substrate, and then measuring the increase in column diameter with film thickness. This model was tested under various conditions [40], which returned good results and an accurate prediction of the relation between the incident angle of the deposition flux and the tilt angle of the columns for several materials.
"
32,S0045782514000607.txt,"['initi residu amplif', 'poor nonlinear converg', 'penal formul', 'penalti method', 'PL formul', 'converg', 'gener formul', 'penalti or static condens PL formul', 'weakli penal formul', 'PL', 'deterior converg', 'weakli penal and PL approach', 'weakli penal', 'inf–sup stabl scheme', 'amplif of the residu', 'classic penalty/weakli penal', 'nonlinear converg']",.,"As mentioned previously, the weakly penalized system can be thought of as a generalized formulation which can result in the PL, penalty or statically condensed PL formulations depending on the choice of the projection operator. The equivalence of these methods under the weakly penalized regime, allows us to combine and take advantage of the good characteristics of each method. For instance, the weakly penalized formulation combines the simplified structure of the penalty method with the convergence characteristics of the PL formulation. However, due to the stiffness of the linear system at high values of the bulk modulus, the penalized formulations (classic penalty/weakly penalized) exhibit deteriorated nonlinear convergence. This stands in stark contrast to the PL method which (for inf–sup stable schemes) exhibits fast convergence even for high bulk modulus. However, we observe that, when the choice of πh provides equivalence with the discrete PL method, poor nonlinear convergence is observed though, in principle, the convergence should be similar. Examining the update formulae for both weakly penalized and PL approaches (see Appendix C), we observe that deteriorated convergence stems from: (1) initial residual amplification, and (2) the amplification of the residual.
"
33,S0021999115008372.txt,"['monge–ampèr equat', 'optim transport (ot) mesh', 'r-adapt mesh gener', 'variat method', 'weather and climat predict', 'monitor function', 'mesh tangl', 'deform a mesh', 'control resolut in differ direct for r-adapt mesh', 'atmospher model', 'mesh redistribut', 'adapt', 'r-adapt', 'optim transport problem on the sphere', 'map of solut between mesh', 'adapt mesh', 'weather and climat predict model', 'repres scale interact', 'mesh', 'monge–ampèr', 'sphere', 'alter the mesh connect', 'scalar valu monitor function', 'r-adapt mesh']",.,"The need to represent scale interactions in weather and climate prediction models has, for many decades, motivated research into the use of adaptive meshes [3,34,38]. R-adaptivity – mesh redistribution – involves deforming a mesh in order to vary local resolution and was first considered for atmospheric modelling more than twenty years ago by Dietachmayer and Droegemeier [14]. It is an attractive form of adaptivity since it does not involve altering the mesh connectivity, does not create load balancing problems because points are never created or destroyed, does not require mapping of solutions between meshes [26], does not lead to sudden changes in resolution and can be retro-fitted into existing models. Variational methods exist which attempt to control resolution in different directions for r-adaptive meshes (e.g. [23,25]). Alternatively, the solution of the Monge–Ampère equation to generate an optimally transported (OT) mesh based on a scalar valued monitor function is a useful form of r-adaptive mesh generation because it generates a mesh equidistributed with respect to a monitor function and does not lead to mesh tangling [7]. We will see that the optimal transport problem on the sphere leads to a slightly different equation of Monge–Ampère type, which has not before been solved numerically on the surface of a sphere, which would be necessary for weather and climate prediction using r-adaptivity.
"
34,S0885230816300043.txt,"['speaker cluster', 'train show-bas acmllr transform', 'anat model', 'anat procedur', 'adapt train', 'factoris approach use mllr speaker transform', 'gmm–hmm model', 'adapt retrain of the gmm–hmm paramet', 'acmllr transform', 'speaker adapt']",.,"The final set of experiments involved an adaptive retraining of the GMM–HMM parameters following the aNAT procedure. This new model only provided an improvement of 0.3%, similar to using the aCMLLR transforms on the baseline GMM–HMM model. However, training show-based aCMLLR transforms on top of the adaptively trained model boosted the improvement to 0.8% absolute. This showed how adaptive training provided a better flexibility of the model to adapt to specific background conditions existing in each show. Finally, the factorisation approach using MLLR speaker transforms on top of the aNAT model and show-based aCMLLR transforms was tested. This only increased the improvement to 0.9% absolute (2.9% relative), which reflects the difficulty of performing accurate speaker clustering in this task and how this actually hampers speaker adaptation.
"
35,S0032386109001712.txt,"['pva', 'crystal', 'simpl polym', 'rapid quench', 'repuls spheric atom', 'full-atomist approach', 'solid', 'classic solid–liquid transit', 'appropri model', 'liquid', 'fold surfac', 'coarse-grain model', 'homogen nucleat', 'crystallin', 'coarse-grain of the system', 'polym', 'polym crystal', 'intrachain interact', 'poly(vinyl alcohol)', 'simul', 'isotrop melt', 'lamella']",.,"With ever increasing computer performance, simulations in much larger systems have become feasible. However, full-atomistic approaches to polymer crystallization need extremely large computer power even in the case of simple polymers, and appropriate modeling or coarse-graining of the system is imperative. From a series of work on the development of coarse-grained models for polymers, Mayer and Muller-Plathe have build up a model of poly(vinyl alcohol) (PVA) for studying early stage of crystallization. They investigated the emergence of crystalline order from the isotropic melt by rapid quenching [51,52]. They could reproduce many elementary processes of homogenous nucleation that showed good correspondence with experiments and other simulations, in temperature dependence of lamella thickness, structure of fold surface, etc. In their work, they neglected long-range force (van der Waals attraction) to accelerate computation. Their model has the energy contribution due to intrachain interactions only and the dominant driving force for crystallization is entropic, which seems to ignore dominant driving force for polymer crystallization in conventional sense. However, their work is reminiscent of the classical solid–liquid transition in systems of repulsive spherical atoms [53] and poses an intriguing problem as to the intrinsic driving force for polymer crystallization.
"
36,S1877750315000575.txt,"['analys what is the effect of real time inform dissemin', 'massiv use of real-tim inform', 'simul', 'inform dissemin in transport system', 'investig the impact of inform on the global network perform', 'build more intellig traffic control mechan']",.,"There are some relevant studies on information dissemination in transportation systems using simulations. One category of studies look at how either local information (only about the neighbours) or global information (about the entire network) affects the global network performance. Our approach is different in the sense that we investigate the impact of information on the global network performance depending on the fraction of people that receive information. We analyse what is the effect of real time information dissemination and explain why this effect appears. Information is disseminated in real time and contains global details about how congested the roads are. This approach is important as it gives insights on the impact that massive use of real-time information can have on traffic. This can be useful for building more intelligent traffic control mechanisms where information is a steering tool.
"
37,S1877750311000676.txt,"['lane select polici', '2D and 3D simul', 'probabilist rout', '‘roulett wheel’ style', 'vehicl', 'driver', 'vissim', 'simul', 'weighbridg', 'graphic microsimul', 'simul toolkit', 'piecewis techniqu', 'probabilist']",.,"One way to enforce this ratio is to use a probabilistic, ‘roulette wheel’ style lane selection policy. VISSIM, along with most simulation toolkits, offers methods to specify probabilistic routing whereby a defined percentage of vehicles are sent down unique routes. This is a piecewise technique that can be reapplied at various locations around a simulation. While these methods are attractive from a calibration perspective as exact representations of existing statistics can be ensured, the process is an unrealistic one as it assumes that drivers make probabilistic decisions at precise locations. So in this case when a vehicle arrives at a point prior to the weighbridges it is allocated one of the lanes based on the respective probabilities. It turns out that this method leads to significant variations in trip times depending on the initial random number seed, this can be seen in a graphic of the key areas of the simulation for the 2 different runs (Fig. 7). One of the benefits of graphical microsimulation is that the 2D and 3D simulations help the researcher to visualise a new scheme and its potential benefits but also to highlight unrealistic behaviour. Fig. 7 shows the congestion at the decision point for 2 different runs. Using probabilistic routing to enforce correct routing percentages is a clear case of overcalibration affecting simulation brittleness.
"
38,S0927025614006181.txt,"['sphere “overlap”', 'contact damp', 'half step leap-frog verlet numer integr scheme', 'contact particl', 'forc', 'linear spring–dashpot–slid analog', 'contact forc', 'particl', 'moment', 'particl centr', 'translat and rotat motion', 'particl cohes', 'particl contact', 'zone method', 'model pack and flow of granular materi', 'discret element method', 'explicit time step approach', 'particl posit', 'inter-particl and particl wall contact', 'granular materi', 'particl elast stiff', 'numer integr', 'sphere', 'veloc', 'particl elast', 'near-neighbour list']",.,"The Discrete Element Method applied to spheres is well established as a reasonably realistic tool, in a wide range of engineering disciplines, for modelling packing and flow of granular materials; Asmar et al. [8] describes the fundamentals of this method as applied by code developed in-house at Nottingham; since these are widely documented the details are not reproduced here, simply a summary. It applies an explicit time stepping approach to numerically integrate the translational and rotational motion of each particle from the resulting forces and moments acting on them at each timestep. The inter-particle and particle wall contacts are modelled using the linear spring–dashpot–slider analogy. Contact forces are modelled in the normal and tangential directions with respect to the line connecting the particles centres. Particle elastic stiffness is set so sphere “overlap” is not significant and moderate contact damping is applied. Particle cohesion can also be modelled but is assumed to be negligible in the current study. The translational and rotational motion of each particle is modelled using a half step leap-frog Verlet numerical integration scheme to update particle positions and velocities. Near-neighbour lists are used to increase the computational efficiency of determining particle contacts and a zoning method is used each time the list is composed; that is the system is divided into cubic regions, each particle centre is within one zone, and potential contacting particles are within the same or next-door neighbour zones. Full details are given in Asmar et al. [8].
"
39,S0168365913009036.txt,"['lcprgpd', 'pdla', 'dotma', 'pdlap1', 'incub', 'dna', 'dope', 'liposom laprg', 'pdlap2', 'ladp', 'lpd', 'lcprg', 'formul anion nanocomplex', 'ad', 'nanocomplex', 'liposom lap1', 'LA', 'liposom lap2', 'rapid mix and incub', 'pdlaprg', 'an anion liposom', 'lap1 or lap2', 'prepar', 'liposom lcprg', 'liposom LA', 'liposom', 'liposom dotma/dop', 'peptid']",.,"Two methods of formulating anionic nanocomplexes were evaluated. In both, nanocomplexes were prepared in water at a range of molar charge ratios of L to D while the peptide P to D molar charge ratio was maintained constant at 3:1. Method 1 (L:D:P): DNA was first added to an anionic liposome (LA, LAP1 or LAP2) and incubated for 15min at room temperature and then the peptide was added with rapid mixing and incubated at room temperature for a further 20min; Method 2 (P:D:L): the peptide was added to the DNA and incubated for 15min at room temperature and then liposome was added with rapid mixing and incubated at room temperature for a further 20min. Irrespective of the method of order of mixing, all molar charge ratios in this study refer to L:P:D. Cationic formulations LPD and LCPRGPD were prepared in the order L:P:D as described previously; first, the peptide was added to the liposome DOTMA/DOPE or LCPRG followed by addition of the DNA with rapid mixing and incubated for 30min at room temperature to allow for complex formation [30]. The nanocomplexes prepared were termed LPD (liposome DOTMA/DOPE), LADP and PDLA (liposome LA), PDLAP1 (liposome LAP1), PDLAP2 (liposome LAP2), PDLAPRG (liposome LAPRG) and LCPRGPD (liposome LCPRG).
"
40,S0045782515001322.txt,"['curv vessel', 'compar analysi', 'stent-graft expans', 'vessel', 'simplifi contact model', 'FE analys', 'FM', 'FM deploy algorithm', 'simul', 'vessel wall', 'contact algorithm', 'node', 'FE', 'FE simul']",.,"One of the most important outcomes of the comparative analysis is the fact that in all tested cases the use of FM is associated with a dramatic reduction in computational time when compared with FE, generally being in the order of seconds for FM and in the order of hours for FE. Table 1 reports the timings of the simulations for both methods. Free expansion is the fastest case, where FM reaches the load-free configuration in just 2 s, while simulations inside the vessels with the diameter of around 30 mm take approximately 30 s. Most of the execution time of the FM deployment algorithm is dedicated to the contact check and calculations of the implications the vessel wall has on the stent structure. Interestingly, in both methods, the highest computational time (i.e., curved vessels) is not associated with the most complex geometry (i.e., patient-specific case of aortic dissection). Another fact worth mentioning is the relation of the computational time to the diameter of the vessel in both methods. While the computational time of FM appeared to be directly related to the diameter of the vessel, no immediate relation was found for the FE simulations. Such outcome is probably related to the simplified contact model used by FM, which makes the stent-graft expansion terminate once the nodes come in contact with the vessel wall. On the contrary, it is well known that the contact algorithm used in the FE analyses increases the computational cost of the simulations.
"
41,S0039602899010869.txt,"['macroscop van der waal forc', 'tip–surfac separ', 'sampl atom', 'atom', 'semi-infinit substrat', 'calcul', 'van der waal interact', 'macroscop part of the tip', 'van der waal forc', 'macroscop Si tip', 'dispers forc']",.,"The final contribution to the force is the van der Waals interaction. It includes the following contributions: (i) between the macroscopic Si tip of conical shape with the sphere of radius R at the end [27] and semi-infinite substrate; (ii) the dispersion forces between the atoms in the sample treated atomistically; and (iii) the interaction between the macroscopic part of the tip and the sample atoms. The first contribution is calculated analytically [27]. In fact, the macroscopic contribution to the van der Waals force is the same in each of the three systems described below, as it depends only on the tip–surface separation, macroscopic sphere radius, cone-angle and Hamaker constant of the system [27]. All these quantities are identical in each system we look at, so that the van der Waals force acts as a background attractive force independent of the microscopic properties of the system [8]. The Hamaker constant needed for the calculation of the macroscopic van der Waals force is estimated to be 0.5eV [32].
"
42,S0032386109001463.txt,"['even polygon theorem', 'three-branch molecul', 'mont carlo simul', 'cylind', 'polym chain', 'three interfac', 'chain entropi', 'b/c and c/a', 'a/b', 'star molecul', 'polygon', 'diagon bond method']",.,"When incompatible three component polymer chains are tethered at a junction point, the resultant star molecules of the ABC type are in a very frustrated field in bulk. That is, their junction points cannot be aligned on two-dimensional planes but on one-dimensional lines, as schematically shown in Fig. 1. Furthermore, when the chain length difference is not so large, the array of junction points tends to be straight and long one. Consequently each domain with mesoscopic sizes becomes cylinders, and their cross sections could be conformed by polygons [28,29]. This is because three interfaces, A/B, B/C and C/A are likely to be flat since there exist no junction points at interfaces and therefore chain entropy contribution to the free energy of structure formation is considerably small comparing with regular block and graft copolymer systems. As a matter of fact, Dotera predicted several tiling patterns by the diagonal bond method, a new Monte Carlo Simulation [30], while Gemma and Dotera pointed out that only three regular tilings, i.e., (6.6.6), (4.8.8) and (4.6.12) are permitted for three-branched molecules proposed as the “even polygon theorem” [31].
"
43,S2212671612000431.txt,"['face recognit system', 'lbp', 'local binari pattern', 'face recognit', 'preprocess', 'geometr normal', 'eye locat', 'eye locat method', 'eyebal search', 'adaboost algorithm', 'recognit', 'pre-process of the face', 'symbian platform', 'face preprocess', 'illumin normal', 'ER']",.,"In this paper, an implementation of a LBP (local binary pattern) based fast face recognition system on symbian platform is presented. First, face in picture taken from camera is detected using AdaBoost algorithm. Second, the pre-processing of the face is done, including eye location, geometric normalization, illumination normalization. During the face preprocessing, a rapid eye location method named ER (Eyeball Search) is proposed and implemented. Last, the improved LBP is adopted for recognition. Although the computational capability of the symbian platform is limited, the experimental results show good performance for recognition rate and time. in pressIn this paper, an implementation of a LBP (local binary pattern) based fast face recognition system on symbian platform is presented. First, face in picture taken from camera is detected using AdaBoost algorithm. Second, the pre-processing of the face is done, including eye location, geometric normalization, illumination normalization. During the face preprocessing, a rapid eye location method named ER (Eyeball Search) is proposed and implemented. Last, the improved LBP is adopted for recognition. Although the computational capability of the symbian platform is limited, the experimental results show good performance for recognition rate and time. in press
"
44,S0370269304005829.txt,"['neutrino flux', 'reactor case', 'electron', 'electron recoil', 'helium-6 ion', 'static tritium sourc', 'electron–neutrino scatter', 'neutrino magnet moment', 'neutrino', 'beta-beam', 'beta-beam sourc']",.,"Let us now consider the case of a beta-beam source. Similarly to the case of a static tritium source, an advantage of the beta-beams is that the neutrino fluxes can be very accurately calculated. Fig. 3 shows the electron–neutrino scattering events in the range of 0.1 MeV to 1 MeV and 1 keV to 10 keV, respectively. (In Fig. 3(b) we have rounded to the nearest integer number of counts.) The shape of the flux-averaged cross sections is very similar to the reactor case as reflected in the event rates shown in the figures. As can be seen, by measuring electron recoils in the keV range with a beta-beam source one could, with a sufficiently strong source, have a very clear signature for a neutrino magnetic moment of 5×10−11μB. These figures are for Helium-6 ions, however, similar results can be obtained using neutrinos from 18Ne. The results shown are obtained for an intensity of 1015 ν/s (i.e., 1015  ions/s). If there is no magnetic moment, this intensity will produce about 170 events in the 0.1 MeV to 1 MeV range per year and 3 events in the 1 keV to 10 keV range per year. These numbers increase to 210 and 55, respectively, in the case of a magnetic moment of 5×10−11μB.
"
45,S221450951400031X.txt,"['cathod protect of the pier', 'detail design', 'look at the system instal previous and calcul', 'vari amount of steelwork', 'asr', 'galvan system', 'broadband connect', 'signific reduct in the number of zone and monitor probe', 'system instal previous', 'encapsul', 'galvashield CC anod', 'depolar of the galvan system', 'multipl layer of mesh', 'data']",.,"This phase was completed in 2005. Previous contracts had been procured with the contractor providing the detailed design. For this system the design was undertaken by Mott MacDonald. It was developed by looking at the systems installed previously and calculating what was actually required to achieve cathodic protection of the piers. This resulted in a significant reduction in the number of zones and monitoring probes. The varying amounts of steelwork in the beams had previously lead to up to 5 zones per beam, with multiple layers of mesh to achieve the design current density. On review of the data the operating current density was similar in all zones and so this was reduced to a single zone per beam. The encapsulation was susceptible to ASR and contained post tensioning and so it was decided to use a galvanic system based on Galvashield CC anodes from Fosroc. Our design did not include an option to allow depolarization of the galvanic system, but the contractor supplied one, such that the anodes could be remotely disconnected. The control unit was from Electrotech CP and operated via a broadband connection provided by the contractor.
"
46,S0021999114007396.txt,"['new regular result', 'one- and two-dimens', 'numer experi', 'finit differ discret of the caputo fraction deriv', 'fulli discret scheme', 'numer scheme', 'empir converg rate', 'multipl caputo fraction deriv in time', 'galerkin scheme', 'multi-term time fraction diffus equat', 'galerkin finit element method']",.,"In this work, we have developed a simple numerical scheme based on the Galerkin finite element method for a multi-term time fractional diffusion equation which involves multiple Caputo fractional derivatives in time. A complete error analysis of the space semidiscrete Galerkin scheme is provided. The theory covers the practically very important case of nonsmooth initial data and right hand side. The analysis relies essentially on some new regularity results of the multi-term time fractional diffusion equation. Further, we have developed a fully discrete scheme based on a finite difference discretization of the Caputo fractional derivatives. The stability and error estimate of the fully discrete scheme were established, provided that the solution is smooth. The extensive numerical experiments in one- and two-dimension fully confirmed our convergence analysis: the empirical convergence rates agree well with the theoretical predictions for both smooth and nonsmooth data.
"
47,S0022311515300830.txt,"['compound', 'oxygen', 'refer materi', 'data process', 'heat flow', 'xrd', 'solid piec', 'argon', 'mdhtc-96', 'drop detector', 'background subtract and peak integr', 'Al', 'high puriti standard metal', '2–4 drop of bi2uo6 sampl', 'correct', 'enthalpi increment', 'setaram multi-detector high temperatur calorimet', 'platinum ingot', 'isotherm run', 'Ni', 'platinum', 'measur the enthalpi increment', 'calorimetr measur', 'Zn', 'Ag', 'Sn', 'commerci avail softwar for data process', 'Pb']",.,"Solid pieces of 23–114 mg were further used to measure the enthalpy increments using a Setaram Multi-detector High Temperature Calorimeter (MDHTC-96) using a drop detector. For more details about the technique we refer to our previous studies [9,10]. The measurements were carried out under an argon atmosphere (with an oxygen content of 7 ppm), using pure platinum ingots (64–144 mg) of 99.95 at % purity as a reference material. The temperature range of the experiment was from 430.3 K to 1088.8 K using steps of 50 K. Each isothermal run consisted of 2–4 drops of Bi2UO6 samples, each surrounded by two drops of platinum from which the sensitivity of the device was determined. The drops were separated by time intervals of 20 min, long enough to re-stabilize the monitored heat flow signal. Background subtraction and peak integration were performed using commercially available software for data processing. The reported temperatures were corrected in accordance with the calibration curve obtained prior to measurement using several high purity standard metals (Sn, Pb, Zn, Al, Ag, Ni) with various melting temperatures in order to cover the whole temperature range of the measurement. After drop calorimetric measurements at the maximum considered temperature, the material was subjected to a new XRD measurement, confirming the stability of the compound under the experimental conditions.
"
48,S0257897213004131.txt,"['uncoat az31 magnesium alloy', 'test time', 'reduct of friction coeffici', 'uncoat az31', 'electrolyt', 'wear process', 'al2o3 nanoparticl', 'nano-particl', '“roll effect”', 'composit coat', 'anod coat without al2o3 nanoparticl', 'reduc friction', 'composit anod coat', 'spheric nanoparticl', 'anod coat', 'friction coeffici', 'coat']",.,"Fig. 7 shows the relationship between the testing time and friction coefficients of various samples under dry conditions. There exist running in and steady wear period in the wear process of uncoated AZ31 and anodizing coating without Al2O3 nanoparticles while there has a steady wear period only in the wear process of composite anodizing coating with Al2O3 nanoparticles. At the same time, the addition of nano-particles to electrolyte led to reduction of friction coefficient. The friction coefficient of composite coating is relatively lower and more stable than what has been reported in literature [24,25] for anodizing coatings. This may be caused by “rolling effect” made by Al2O3 nanoparticles on the surface of oxide coating. Spherical nanoparticles change sliding into rolling, which reduce friction, making the friction coefficient becomes more stable. The friction coefficient of anodizing coating without Al2O3 nanoparticles has large fluctuation maybe for the damage of coating. In contrast to the uncoated AZ31 magnesium alloy, the anodizing coatings show slightly lower friction coefficient. This can be attributed to their higher load-bearing capacity for high hardness.
"
49,S0022311513011951.txt,"['swell', 'grain', 'od particl', 'void', 'migrat of vacanc and sia', 'diffus', 'structur', 'disloc loop', 'displac cascad', 'defect']",.,"The displacement cascade is a rapid process (of order picoseconds). Further migration of vacancies and SIAs, mainly by diffusion, happens over a timescale of order nanoseconds [17]. This is still short compared to operating times, so is important to consider the equilibrium result of such processes: If the vacancies and SIAs were likely to find their Frenkel partner, recombine, and annihilate, then the metal should essentially return to its original structure; however, if defects instead formed large clusters of a single type this could result in formation of voids, dislocation loops or swelling, possibly weakening the material in the process. Defects can be trapped at grain boundaries or surface, so for an ODS particle to effect the diffusion, there concentration must be such that there are many such particles in each grain.
"
50,S0370269304006768.txt,"['renormalis', 'nfinit deriv expans', 'brst terminolog', 'brst cohomolog theorem', 'invari extens of local function', 'non-loc found', 'function which is local in a particular gaug', 'notion of renormalis', 'gaug invari extens of local function', 'infrar mode', 'gaug independ renormalis', 'it gaug invari extens', 'expect valu']",.,"In our study we illustrate the properties of gauge invariant extensions of local functionals. We aim at clarifying, via specific examples, the relation between a functional which is local in a particular gauge (but not necessarily gauge invariant), and its gauge invariant extension (which is not necessarily local). We show that the non-localities found are not perturbatively local because they cannot be expressed in terms of an infinite derivative expansion. We believe that the implications of this observation have not been clearly emphasised in the literature, as attested by the absence of any debate about it in recent works. It is precisely these dangerous infrared modes that make it hard to define a gauge independent renormalisation for the gauge invariant extensions of local functionals. This observation supports the remark in [2] that the expectation value receives important contributions from both large and small distances. Our arguments on renormalisability are based on the notion of renormalisation in the modern sense [8] which relies on BRST cohomology theorems. The BRST terminology will therefore be frequently used here, even though it is not always necessary.
"
51,S037026930400680X.txt,"['yukawa coupl in the quark and charg lepton sector', 'quark', 'see-saw mechan', 'δm2 valu can be fit by take the spectrum of rhd neutrino mass', 'quark sector', 'light neutrino mass', 'rhd neutrino mass', 'yukawa coupl', 'θ12 and θ23 mix angl', 'the angle\xa0θ13', 'mr∼1010–1015', 'charg lepton sector', ""hierarchy-fre mass impli by the δm2'"", 'hierarch neutrino yukawa coupl']",.,"Certainly therefore the see-saw mechanism is an attractive explanation of why the light neutrino masses are so small. However, it is not without its faults. In particular, there is a tension between the strongly hierarchical nature of the observed Yukawa couplings in the quark and charged lepton sectors, and the essentially hierarchy-free masses implied by the Δm2's. Moreover, both the θ12 and θ23 mixing angles are large while the angle θ13 is small which is in sharp contrast with the corresponding mixings in the quark sector which are all small. These problems can be solved in specific models, for example, the Δm2 values can be fitted by taking the spectrum of rhd neutrino masses to be hierarchical in such a way as to almost compensate for the hierarchical neutrino Yukawa couplings. But this has the price of introducing a wide range of rhd neutrino masses MR∼1010–1015 which then require explanation.
"
52,S0166361516300926.txt,"['erp modul', 'ess', 'hybrid erp system', 'erp instal', 'enterpris social softwar', 'erp system']",.,"This research traces the implementation of an information system in the form of ERP modules covering tenant and contract management in a Chinese service company. Misalignments between the ERP system specification and user needs led to the adoption of informal processes within the organisation. These processes are facilitated within an informal organisational structure and are based on human interactions undertaken within the formal organisation. Rather than to attempt to suppress the emergence of the informal organisation the company decided to channel the energies of staff involved in informal processes towards organisational goals. The company achieved this by harnessing the capabilities of what we term a hybrid ERP system, combining the functionality of a traditional (formal) ERP installation with the capabilities of Enterprise Social Software (ESS). However the company recognised that the successful operation of the hybrid ERP system would require a number of changes in organisational design in areas such as reporting structures and communication channels. A narrative provided by interviews with company personnel is thematised around the formal and informal characteristics of the organisation as defined in the literature. This leads to a definition of the characteristics of the hybrid organisation and strategies for enabling a hybrid organisation, facilitated by a hybrid ERP system, which directs formal and informal behaviour towards organisational goals and provides a template for future hybrid implementations.
"
53,S0168365912006207.txt,"['biomimet materi', 'electrospin', 'self-assembl', 'convent manufactur method', 'collagen-mimet pa', 'tune and optim', 'PA nanofib', 'achiev fiber-lik structur', 'robust of self-asseml pa to electrospun nanofib', 'costli manufactur method', 'a full-fledg commerci medic product', 'inject in vivo into model and spontan self-assembl into nanofib in aqueou solut', 'large-scal commerci product', 'pa', 'compar and contrast', 'a manufactur method']",.,"Unlike conventional materials used in nerve tissue engineering, PAs can be directly injected in vivo into models and spontaneously self-assemble into nanofibers in aqueous solutions. Furthermore, PAs can function as biomimetic materials exemplified by collagen-mimetic PAs [92]. Conventional materials often rely on electrospinning as a manufacturing method to achieve fiber-like structures suitable for use in nerve regeneration. The self-assembly nature of PAs allows them to circumvent costly manufacturing methods. However, in contrast to conventional manufacturing methods like electrospinning where quality and batch-to-batch variability can be tightly controlled, merely relying on self-assembly as a method of large-scale commercial production is still an experimental concept. Perhaps the next step would be to carefully compare and contrast the robustness of self-assemled PAs to electrospun nanofibers. Given that the constituent elements in PAs and external factors like pH can affect its structural assembly, parameters must be finely tuned and optimized in order for PA nanofibers to be used as a full-fledged commercialized medical product [93].
"
54,S0022311511010014.txt,"['channel event', 'collis cascad', 'Ga', 'low energi cascad in Pu and puga', 'energet atom travel deep into the lattic through channel of low atom densiti', 'Ga atom', 'defect migrat pathway', 'cascad event']",.,"Discovering that both the vacancy and interstitial defect migration pathways are confined to Ga-free regions suggests changes in recombination rates of isolated vacancy-interstitial pairs in comparison to pure Pu. The degree to which the rates are effected depends on the distribution of residual defects post a cascade event, in addition to the concentration and ordering of the Ga atoms. If vacancies and interstitials become greatly separated after the collision cascade, then pathways to recombination are likely to become restricted and recovery times will be extended. This is viable for cascades that created a vacancy rich core surrounded by dispersed interstitials, as found for the low energy cascades in Pu and PuGa [11,12]. This may also be the case for channelling events, where energetic atoms travel deep into the lattice through channels of low atomic density.
"
55,S1687850714000405.txt,"['plant oil and starch', 'liquefact of coffe mucilag', 'non-starchi polysaccharid', 'effici of agricultur silag product', 'pulp and paper industri', 'remov of lignin', 'clarif of juic and wine', 'protoplast of plant cell', 'brighten of the pulp', 'arabinoxylan', 'hydrolysi of non-starchi polysaccharid', 'chlorin free bleach oper', 'extract of flavor and pigment', 'pulp', 'lignin', 'macer of veget matt', 'even redistribut of the water content of the bread', 'xylanas', 'xylan compon', 'bleach agent', 'make liquid coffe', 'anim feed industri', 'wood', 'recoveri of oil from subterranian mine', 'hydrolyz the xylan compon']",.,"Xylanases have potential applications in various fields. Some of the important applications are as fallows. Xylanases are used as bleaching agent in the pulp and paper industry. Mostly they are used to hydrolyzed the xylan component from wood which facilitate in removal of lignin (Viikari, Kantelinen, Buchert, & Puls, 1994). It also helps in brightening of the pulp to avoid the chlorine free bleaching operations (Paice, Jurasek, Ho, Bourbonnais, & Archibald, 1989). In bakeries the xylanase act on the gluten fraction of the dough and help in the even redistribution of the water content of the bread (Wong & Saddler, 1992). Xylanases also have potential application in animal feed industry. They are used for the hydrolysis of non-starchy polysaccharides such as arabinoxylan in monogastric diets (Walsh, Power, & Headon, 1993). Xylanases also play a key role in the maceration of vegetable matter (Beck & Scoot, 1974), protoplastation of plant cells, clarification of juices and wine (Biely, 1985) liquefaction of coffee mucilage for making liquid coffee, recovery of oil from subterranian mines, extraction of flavors and pigments, plant oils and starch (McCleary, 1986) and to improve the efficiency of agricultural silage production (Wong & Saddler, 1992).
"
56,S025405841530136X.txt,"['al–12si alloy', 'inocul', 'α-al dendrit grain', 'nb+b inocul', 'al–si cast alloy', 'fade', 'fine grain structur', 'refin of cast Al alloy', 'cast Al alloy', 'alloy', 'inocul with differ level of nb+b', 'refin of al–si cast alloy', 'grain refin', 'grain refin potenc of nb+b inocul', 'heterogen nucleat substrat', 'B', 'nb-base intermetal compound', 'nb+b', 'enhanc heterogen nucleat', 'lighter structur compon', 'grain', 'Nb', 'wide rang of cool rate']",.,"From this study where a commercial Al–12Si alloy was inoculated with different level of Nb+B addition to assess the grain refining potency of Nb+B inoculation it can be concluded that in-situ formed Nb-based intermetallics compounds are potent heterogeneous nucleation substrates with high potency for the refinement of Al–Si cast alloys. The primary α-Al dendritic grain size varies with the addition level of Nb and B. Moreover, significant grain refinement over a wide range of cooling rates is obtained via enhanced heterogeneous nucleation making the grain size of the material less sensitive to the cooling rate. Nb+B inoculants are characterised by some fading which is still acceptable after 4 h of contact time. Moreover, alloys refined by means of Nb+B inoculants can be recycled obtaining a fine grain structure with small addition or no further addition of inoculants after the first initial addition. Concluding, Nb+B inoculation is a promising candidate for the refinement of cast Al alloy which could lead to their wider employment in the automotive industry with the resultant intrinsic advantages of lighter structural component from an environmental point of view.
"
57,S0045782513001473.txt,"['frame cell', 'volume-averag approach', 'shear stress', 'simpl cell', 'method of plane', 'framed’ cell', 'complic comput cell', 'calcul the stress tensor', 'IK equat', 'lees–edward cell', 'schweitz virial relat', 'constrain the veloc']",.,"In this paper, however, we prefer the simpler ‘framed’ cell employed by Hadjiconstantinou and Patera [16], where the shear stress is generated by constraining the velocity in a ‘frame’ rather than by modifying the shape of the box. The framed cell is periodic, but we cannot simply calculate the average stress in the whole box because the presence of an external buffer would produce spurious results. We need the local stress in the core region, but this complicates the Oij term in Eq. (3). There are other methods to calculate the stress tensor such as the method of planes [32], the volume-average approach [26,14], or the method derived from the Schweitz virial relation [25], but, in general, we must choose between a complicated computational cell (i.e. Lees–Edwards cell) and simplifying the calculation of the momentum flux, or a simple cell (i.e. framed cell) and complicating the calculation of the momentum flux. The new method we propose here does not need the direct calculation of the flux, so it avoids this issue altogether: we can use the framed cell and, at the same time, avoid the calculation of the IK equation.
"
58,S0370269304008792.txt,"['medium neutron–proton cross section', 'studi of the isovector part of the nuclear equat of state', 'δ meson', 'relativist framework', 'isovector meson field', 'σnp', 'introduct of the δ meson in the descript of the iso-vector equat of state', 'scalar δ field to the symmetri energi and the isospin dynam is particularli explor', 'comparison with experi', 'isospin mix', 'relativist energi', 'ru(zr)+zr(ru)', 'investig the densiti behavior of the symmetri energi with respect to isospin equilibr', 'studi', 'contribut of the iso-vector', 'combin system']",.,"We investigate the density behavior of the symmetry energy with respect to isospin equilibration in the combined systems Ru(Zr)+Zr(Ru) at relativistic energies of 0.4 and 1.528A GeV. The study is performed within a relativistic framework and the contribution of the iso-vector, scalar δ field to the symmetry energy and the isospin dynamics is particularly explored. We find that the isospin mixing depends on the symmetry energy and a stiffer behavior leads to more transparency. The results are also nicely sensitive to the “fine structure” of the symmetry energy, i.e., to the covariant properties of the isovector meson fields.The isospin tracing appears much less dependent on the in medium neutron–proton cross sections (σnp) and this makes such observable very peculiar for the study of the isovector part of the nuclear equation of state.Within such a framework, comparisons with experiments support the introduction of the δ meson in the description of the iso-vector equation of state."
59,S0375960115005630.txt,"['electromagnet field', 'laser puls', 'densiti wave', 'stern–gerlach-typ contribut', 'plasma electron', 'electron', 'wave ‘breaks’', 'high-intens laser puls', 'longitudin wave', 'stern–gerlach forc', 'electron damp the wave', 'laser-driven plasma wave', 'plasma', 'high electr field gradient of a plasma wave', 'laser', 'electromagnet field gradient']",.,"The systems in which the Stern–Gerlach force is most prominent are those with a high electromagnetic field gradient. Section 2 considers the implications of the coupling between the spin of a classical electron and the rapidly varying electromagnetic field produced by a laser-driven plasma wave. Sufficiently short, high-intensity laser pulses can form longitudinal waves within the electron density of a plasma. These density waves propagate with speed comparable to the group speed of the laser pulse. Not all plasma electrons form this wave, however; some of the electrons are caught up in the wave and accelerated by its high fields. The wave eventually collapses as these electrons damp the wave (the wave ‘breaks’). The extremely high electric field gradient of a plasma wave near wavebreaking provides an excellent theoretical testing ground for the effects of Stern–Gerlach-type contributions to the trajectory of a test electron.
"
60,S096386951400070X.txt,"['ners', 'electr imped', 'electr reson of an eddi current probe', 'snr', 'defect-decoupl resonance-shift effect', 'imped snr', 'eddi current probe', 'highlight a band of frequenc', 'near electr reson signal enhanc', 'ect inspect']",.,"This paper has highlighted a band of frequencies, outside the conventional operation range, and close to electrical resonance of an eddy current probe, where the magnitude of impedance SNR reaches a peak. The SNR of scans of three slots of varying depth were enhanced by a factor of up to 3.7, from the SNR measured at 1MHz. This is a result of a defect-decoupling resonance-shift effect and is referred to as the near electrical resonance signal enhancement (NERSE) phenomenon. NERSE frequency operation has significant potential for ECT inspection, and opens up a range of investigative possibilities. Within this investigation, only the magnitude of the electrical impedance has been analyzed. An immediate extension of this investigation will be to consider phase information, and determine whether a similar exploitable NERSE effect exists.
"
61,S2212667814001294.txt,"['knowledg manag', 'hybrid recommend approach', 'knowledg manag system', 'real-lif system', 'verifi the propos methodolog', 'KM', 'km', 'role-bas access contro', 'extend', 'rbac', 'defect when exist method about access control and recommend are deploy in km are analyz']",.,"Knowledge Management (KM) is one of the hotspots for research in the past decade. In most cases, the number of users in a Knowledge Management System (KMS) is very large, and they are from varied departments, even other companies. In this paper, some defects when existing methods about access control and recommendation are deployed in KMS are analyzed to show that these widely-used approaches need to be extended. To overcome the deficiencies of previous work, this paper proposes an extended Role-Based Access Control (RBAC) method and a hybrid recommendation approach for Knowledge Management System. Also, a real-life system is presented to verify the proposed methodology."
62,S0370269304009979.txt,"['brane world model', 'warp geometri', 'local on the brane', 'spin\xa00 field is local on a brane', 'five dimens', 'randall–sundrum model', 'standard model', 'local mechan', 'neg tension', 'local', 'six space–tim dimens', 'local the graviton', 'posit tension', 'introduc in the bulk']",.,"On the other hand, the other local fields except the gravitational field are not always localized on the brane even in the warped geometry. Indeed, in the Randall–Sundrum model in five dimensions [2], the following facts are well known: spin 0 field is localized on a brane with positive tension which also localizes the graviton while the spin 1/2 and 3/2 fields are localized not on a brane with positive tension but on a brane with negative tension [6]. Spin 1 field is not localized neither on a brane with positive tension nor on a brane with negative tension [7]. In six space–time dimensions, the spin 1 gauge field is also localized on the brane [8]. Thus, in order to fulfill the localization of Standard Model particles on a brane with positive tension, it seems that some additional interactions except the gravitational interaction must be also introduced in the bulk. There is a lot of papers devoted to the different localization mechanisms of the bulk fields in various brane world models.
"
63,S0301010414003516.txt,"['ambient air', 'vacuum-fabr procedur', 'evapor', 'plasma', 'vacuum', 'substrat', 'drum', 'track', 'aluminium gate electrod', 'web-coat drum', 'polyethylen naphthal (pen) substrat', 'exposur', 'tft', 'polyethylen naphthal', 'flash-evapor tpgda monom vapour', 'insul', 'circuit', 'pen', 'gold source/drain metallis layer', 'vacuum evapor', 'film', 'vacuum-deposit', 'cross-link', 'inter-lay metal connect', 'nitrogen glovebox', 'shadow mask', 'circuit fabric']",.,"Arrays of TFTs and circuits were fabricated on precleaned, 5cm×5cm, 125μm thick polyethylene naphthalate (PEN) substrates (Dupont-Teijin). Full details of our vacuum-fabrication procedures have been given in previous publications [17–19,23]. Briefly, aluminium gate electrodes and associated tracks were vacuum evaporated onto the substrates through shadow masks. Subsequently, the substrates were attached to a cooled web-coater drum (Aerre Machines). With the drum rotating at a linear speed of 25m/min under vacuum, flash-evaporated TPGDA monomer vapour which condensed onto the substrates was cross-linked by exposure, in situ, to a plasma. The resulting smooth, pinhole-free films were typically 500nm to 1μm thick with a measured dielectric constant varying in the range 4–5. For circuit fabrication, the insulator was patterned using shadow masks to define rectangular areas separated by 1mm gaps to act as vias for inter-layer metallic connections. The substrates were then transferred into an evaporator (Minispectros, Kurt Lesker) integrated into a nitrogen glovebox for the vacuum-deposition (2.4nm/min) of DNTT onto the insulator. Without exposing the substrates to ambient air, the gold source/drain metallisation layer was deposited through a shadow mask in the same evaporator.
"
64,S0009261415000974.txt,"['physic relev minima', 'alanin dipeptid', 'larger potenti energi space', 'cross-ov in the approxim global free energi', 'forc field and solvent model', 'balanc between potenti energi and well entropi', 'rang of temperatur chosen']",.,"Within the range of temperatures chosen, alanine dipeptide exhibits very simple behaviour. This result is due to the relatively small number of physically relevant minima (seven were characterised using this force field and solvent model) and the larger potential energy spacing between the global minimum and higher energy minima. Indeed, cross-overs in the approximate global free energy minimum for this system (where the free energy of the second-lowest potential energy minimum becomes lower than that of the global potential energy minimum) in the harmonic approximation would occur at 1170K. In general, the harmonic prediction for the crossover temperature between two minima is(4)kBTxo=V1−V2ln((o2ν¯2κ)/(o1ν¯1κ)),from Eq. (3), which clearly illustrates the balance between potential energy and well entropy.
"
65,S2212667812000937.txt,"['gener of logic reason question', 'AI techniqu', 'verbal question', 'question gener for job interview', 'algorithm for automat gener of logic reason questions.', 'construct question that are solvabl with uniqu solut', 'semant network', 'memori constrain mobil platform', 'tradit question databas']",.,"In this paper, we present algorithms for automatic generation of logic reasoning questions. The algorithms are able to construct questions that are solvable with unique solutions. The algorithms employ AI techniques such as semantic networks to produce verbal questions. These algorithms are small in size and are able to replace traditional question databases. They are particularly suitable for implementation on the memory constrained mobile platforms. The algorithms can be applied to question generation for job interview, civil service exam, etc."
66,S2212671612002351.txt,"['refract of prism', 'robust', 'geometr optic', 'effect', 'extend the applic of single-len stereovis system', 'posit estim method', 'mathemat model', 'refract plane', 'imag', 'transform matrix', 'singl optic system', 'express the relationship', 'single-len stereovis system', 'object point', 'prism']",.,"In this paper, a novel position estimation method of prism was proposed for single-lens stereovision system. The prism with multi faces was considered as a single optical system composed of some refractive planes. A transformation matrix which can express the relationship between an object point and its image by the refraction of prism was derived based on geometrical optics, and a mathematical model was introduced which can denote the position of prism with arbitrary faces only by 7 parameters. This model can extend the application of single-lens stereovision system using prism to a more widely area. Experimentation results are presented to prove the effectiveness and robustness of our proposed model."
67,S0009261408017028.txt,"['vibrat combin state', 'measur thi cumul thermal effect', 'high repetition-r laser', 'optical-chopp', 'cumul thermal effect', 'alcohol', 'absorpt', '1560nm femtosecond laser puls', 'non-radi process', 'primari alcohol', 'water', 'mode-mismatch two-color pump–prob experi', 'apertur z-scan experi', 'femtosecond laser puls at 1560nm', 'molecul', 'pure optic nonlinear', 'transient thermal effect', 'satur absorpt']",.,"We use open and close aperture Z-scan experiments, in analogy to the saturation absorption work discussed earlier in water [8], to respectively measure the β and n2 for a series of primary alcohols with the help of 1560nm femtosecond laser pulses, however, with the important inclusion of an optical-chopper. The vibrational combination states of the alcohols are coupled by the femtosecond laser pulses at 1560nm. These couplings result in the absorption of 1560nm and the excited molecules undergo relaxation through non-radiative processes, which gives rise to transient thermal effects. These transient thermal effects are related to the pure optical nonlinearity of the samples and can be measured as a change in their n2 values [14]. The transient thermal effects of individual pulses accumulate in case of high repetition-rate lasers to produce a cumulative thermal effect at longer timescales. We measure this cumulative thermal effect with the mode-mismatched two-color pump–probe experiment.
"
68,S0009261412012365.txt,"['decay constant', 'norbornen', 'norbornadien', 'parent ion', 'best fit decay constant', 'curv fit levenberg–marquardt algorithm', 'laser control principl', 'fragment of dcpd to cpd', 'two-step decay model', 'reaction', 'control the product yield of c5h6+', 'parent ion fragment', 'further ioniz', 'τ1=35f', 'matlab® program', 'c10h12+ ion signal', 'c10h12+', 'transient', 'c5h6+ ion signal', 'dcpd', 'observ dynam', 'appli laser control principl', 'photochem reaction of dcpd', 'τ1=36f', 'τ2=280f', 'biexponenti decay compon', 'distinct dynam of the neutral', 'rise and decay compon', 'c5h6+', 'τ2=240f', 'cpd', 'probe laser']",.,"Under these experimental conditions, the observed dynamics has to occur where the probe laser induces the reactions resulting in further ionization [30]. The two-step decay model [26] was applied to explain the above-mentioned fragmentation of DCPD to CPD, shown in Figure 8a. The fitting of the rise and decay components of the transients were done by Matlab® programming using the curve fitting Levenberg–Marquardt algorithm. The best fit decay constants for the biexponential decay components of C10H12+ ion signal is τ1=35fs and τ2=240fs, while that for C5H6+ ion signal is τ1=36fs and τ2=280fs, respectively. These decay constants conform to the previously reported time constants of norbornene and norbornadiene [22,23]. The transients of the reaction fragment C5H6+ are sufficiently different from that of the parent ion C10H12+ indicating that we are studying the distinct dynamics of the neutrals and not that of the parent ion fragmentation [24]. Applying laser control principles under such experimental circumstances also confirms that we are controlling the product yield of C5H6+, resulting from the photochemical reaction of DCPD.
"
69,S0370269303015478.txt,"['unitar constraint', 'h0', 'investig the quantum effect in the decay of the light cp-even higg boson h0', 'unitar bound', 'quantum effect', 'perturb expans', 'SM', 'loop-improv unitar bound', 'higg boson', 'decoupl regim', 'tree-level analysi', 'high-energi approxim', 'look for sizeabl differ with respect to the SM in the decoupl regim', 'equival theorem', 'exact bound', 'tree-level unitar bound', 'tree level analysi', 'gauge-boson mass', 'decay of the light cp-even higg boson h0']",.,"Since perturbative expansion is used, it is impossible to find the exact bounds; instead, one can derive tree-level unitarity bounds or loop-improved unitarity bounds. In this study, we will use unitarity bounds coming from a tree-level analysis [20]. This tree level analysis is derived with the help of the equivalence theorem [21], which itself is a high-energy approximation where it is assumed that the energy scale is much larger than the Z0 and W± gauge-boson masses. We will consider here this “high-energy” hypothesis that both the equivalence theorem and the decoupling regime are well settled, but in such a way that the unitarity constraint is also fulfilled. Our purpose is to investigate the quantum effects in the decays of the light CP-even Higgs boson h0, especially looking for sizeable differences with respect to the SM in the decoupling regime.
"
70,S0021999115001412.txt,"['uniaxi activ agent', 'theori of activ polar viscou gel', 'constitut equat', 'activ polar viscou gel', 'along with conserv of momentum', 'viscou bulk medium', 'model the continuum', 'cortic cytoskeleton flow', 'polar viscou gel', 'continuum hydrodynam descript', 'these equat', 'biolog morphogenesi', 'uniaxi polar agent', 'fluid', 'gel', 'non-newtonian fluid', 'equat of motion', 'polar field', 'energi consum', 'macroscop mechan', 'anisotrop']",.,"Inspired by energy-fueled phenomena such as cortical cytoskeleton flows [46,45,32] during biological morphogenesis, the theory of active polar viscous gels has been developed [37,33]. The theory models the continuum, macroscopic mechanics of a collection of uniaxial active agents, embedded in a viscous bulk medium, in which internal stresses are induced due to dissipation of energy [41,58]. The energy-consuming uniaxial polar agents constituting the gel are modeled as unit vectors. The average of unit vectors in a small local volume at each point defines the macroscopic directionality of the agents and is described by a polarization field. The polarization field is governed by an equation of motion accounting for energy consumption and for the strain rate in the fluid. The relationship between the strain rate and the stress in the fluid is provided by a constitutive equation that accounts for anisotropic, polar agents and consumption of energy. These equations, along with conservation of momentum, provide a continuum hydrodynamic description modeling active polar viscous gels as an energy consuming, anisotropic, non-Newtonian fluid [37,33,32,41]. The resulting partial differential equations governing the hydrodynamics of active polar viscous gels are, however, in general analytically intractable.
"
71,S2212667812000536.txt,"['softwar industri', '“triple-driven” three-dimension softwar develop practic teach system', 'softwar develop', 'practic skill', 'improv the softwar develop capabl and innov sens of student', 'softwar develop process']",.,"According to the situation that the IT students can not meet the software industry demand for qualified personnel, a “triple-driven” three-dimensional software development practical teaching system was proposed, aiming to improve the software development capabilities and innovation sense of students. This system can effectively improve students the interest of software development and the practical skills and sense of innovation, laying a solid foundation for student after graduation to rapidly integrate into the software development process, meeting the needs of software industry."
72,S0165168416300603.txt,"['gcc-phat', 'generalis cross correl phase transform', 'kalman filter', 'speaker', 'src-he', 'voic activ detector', 'gcc algorithm', 'ekf', 'gcc-phat step', 'speech segment', 'vad', 'm-th microphon pair', 'audio posit estim']",.,"Despite the fact that SRC-HE reduces the number of FEs, audio measurements extraction based on SRC would still be not suitable for real-time applications [39]. The previous SRC-HE module is then replaced by the generalised cross correlation phase transform (GCC-PHAT) introduced in Section 2.1, as this does not involve cumbersome point function estimations. The drawback is that the basic GCC algorithm can only detect one source at a time and it is known to be sensitive to room reverberations [5], however it is still effective under moderate reverberant environments (T60≈0.3s) [40]. For these reasons, at first experiments where only a speaker is active at any given time are carried out, as it often happens in a polite conversation between two or more people. Speech segments using a voice activity detector (VAD) [41] are further extracted and processed using a GCC-PHAT step, for the signal to be more robust to reverberations. Thus, the measure vector obtained za (see Section 2.1) can now be rewritten as za={τm(t)}, where each component τm is the TDOA collected at the m-th microphone pair at each time step t. Since TDOAs are not linear in the speaker position, they must be input into an extended Kalman filter (EKF), as in [10] to get an audio position estimation.
"
73,S0167273815004130.txt,"['powder x-ray diffract', 'stoe win xpow softwar', 'total conduct', 'flow', 'feg-sem', 'gold wire contact', 'xrd', '5% h2/ar', 'conduct', 'panalyt empyrean diffractomet', 'perovskit', 'h2/ar', 'thermogravimetr analysi', 'calcin', 'reduc condit', 'proteu thermal analysi softwar', 'field emiss 74 scan electron microscop', 'low oxygen partial pressur', 'crystal structur', 'weight chang', 'cell paramet', 'four-termin method', 'netzsch sta 449c instrument', 'xrd pattern', 'phase puriti', 'tga', 'redox cycl']",.,"Room temperature powder X-ray diffraction (XRD) was performed on a PANalytical Empyrean diffractometer. The obtained XRD patterns were analysed with STOE Win XPOW software in order to determine phase purity, the crystal structure and the cell parameters of the samples. Thermogravimetric analysis (TGA) was performed using a Netzsch STA 449C instrument equipped with Proteus thermal analysis software. The TGA studies were carried out under reducing conditions (5% H2/Ar) from room temperature to 900°C, in order to determine the weight change of the perovskite during the reduction. The microstructure of the samples' surface was analysed using a JEOL JSM-6700 field emission 74 scanning electron microscope (FEG-SEM). The total conductivity of the samples was measured using a conventional four-terminal method. Bar samples were prepared by calcination at 1300°C for 1h. Gold wire contacts were attached to the bars, which then were cured at 850°C for 1h. The conductivity of the samples was measured under a redox cycle at 900°C. Low oxygen partial pressure was achieved by using a continuous flow of 5% H2/Ar.
"
74,S0370269304009141.txt,"['longitudin beam and target single-spin asymmetri', 'collin function', 'single-particl inclus di', 't-odd fragment function', 'receiv contribut also from t-odd distribut function', 'factor', 't-odd distribut function', 'exhaust treatment of the contribut of t-odd distribut function', 'sublead order in an expans in\xa01/q', 'subleading-twist transverse-momentum depend function', 'e+p→e′+h+x', 'twist distribut', 'factor proof for observ contain subleading-twist transverse-momentum depend function', 'single-jet inclus di', 'quark', 'herm and cla experiment collabor', 'quark mass correct', 'incid photon', 'describ the longitudin beam and target spin asymmetri', 'proof for the leading-twist case', 'fragment function', 'e+p→e′+jet+x']",.,"Longitudinal beam and target single-spin asymmetries have been at the center of the attention lately, since they have been measured by the HERMES and CLAS experimental Collaborations [1–4] and more measurements are planned. They were originally believed to be signals of the so-called T-odd fragmentation functions [5], in particular, of the Collins function [6–12]. However, both types of asymmetry can receive contributions also from T-odd distribution functions [13–16], a fact that has often been neglected in analyses. An exhaustive treatment of the contributions of T-odd distribution functions has not been carried out completely so far, especially up to subleading order in an expansion in 1/Q, Q2 being the virtuality of the incident photon and the only hard scale of the process, and including quark mass corrections. It is the purpose of the present work to describe the longitudinal beam and target spin asymmetries in a complete way in terms of leading and subleading twist distribution and fragmentation functions. We consider both single-particle inclusive DIS, e+p→e′+h+X, and single-jet inclusive DIS, e+p→e′+jet+X. We assume factorization holds for these processes, even though at present there is no factorization proof for observables containing subleading-twist transverse-momentum dependent functions (only recently proofs for the leading-twist case have been presented in Refs. [17,18]).
"
75,S0098300412001793.txt,"['recalcul of amphibol analys', 'amph class', 'ilmat', 'provid miner formula recalcul combin with the associ propag of the analyt uncertainti', 'hyper-form', 'to provid user with greater flexibl in data report', 'recalcul of pyroxen analys', 'some gener program', 'recalcul the formula of multipl miner', 'incorpor the associ uncertainti propag calculations.', 'miner', 'recalcul of magnetit and ilmenit', 'recalcul of multipl common miner', 'a new matlab® base program', 'method', 'probe amph', 'allow user with littl or no experi oper matlab® and/or perform miner formula recalcul and uncertainti propag to undertak both with eas', 'calcmin', 'miner (miner error analysis)', 'px-nom']",.,"MINERAL (MINeral ERror AnaLysis) is a new MATLAB® based program that provides mineral formula recalculations combined with the associated propagation of the analytical uncertainties. Methods are based on the work of Giamarita and Day (1990). However, additional features have been added to provide users with greater flexibility in data reporting. Many programs exist to recalculate wt% data into formula unit cations. Some generalized programs can be used to recalculate the formula of multiple minerals e.g. CALCMIN (Brandelik, 2009) and HYPER-FORM (De Bjerg et al., 1992). Other programs are mineral specific e.g. AMPH CLASS (Esawi, 2004) and PROBE AMPH (Tindle and Webb, 1994) for the recalculation of amphibole analyses; ILMAT (Lepage, 2003) for the recalculation of magnetite and ilmenite; and PX-NOM (Sturm, 2002) for the recalculation of pyroxene analyses. MINERAL provides a rapid method for the recalculation of multiple common minerals. However, its strength lies in the fact that is the first tool to incorporate the associated uncertainty propagation calculations. As these are performed concurrently with the standard recalculations, no additional time is needed to perform uncertainty propagation. While an understanding of the underlying calculations is strongly recommended, MINERAL is designed to allow users with little or no experience operating MATLAB® and/or performing mineral formula recalculations and uncertainty propagation to undertake both with ease.
"
76,S0021999115003459.txt,"['boundari element method', 'solv problem in unbound domain', 'fast bem in shape optimis', 'fast multipol method', 'shape deriv', 'primari and the adjoint boundari valu problem', 'shape optimis of high-voltag devic', 'shape optimis', 'bernoulli-typ free-boundari problem', 'bem', 'surfac discretis', 'electrostat field analysi', 'adjoint approach', 'gradient-bas shape optimis']",.,"The boundary element method (BEM) has clear advantages when applied to shape optimisation of high-voltage devices, see [4–8] for an introduction to BEM. First of all, BEM relies only on a surface discretisation so that there is no need to maintain an analysis-suitable volume discretisation during the shape optimisation process. Moreover, BEM is ideal for solving problems in unbounded domains that occur in electrostatic field analysis. In gradient-based shape optimisation the shape derivative of the cost functional with respect to geometry perturbations is needed [9–11]. To this purpose, we use the adjoint approach and solve the primary and the adjoint boundary value problems with BEM. The associated linear systems of equations are dense and an acceleration technique, such as the fast multipole method [12,13], is necessary for their efficient solution. For some recent applications of fast BEM in shape optimisation and Bernoulli-type free-boundary problems we refer to [14–16].
"
77,S2212667812000664.txt,"['move plate recognit system', 'move plate recognit', ""analysi of move plate recognit system' basic principl"", 'appli the algorithm to pr', 'research on the move plate recognit algorithm', 'move plate recognit algorithm', 'pca', 'pca extract algorithm', 'color extraction.', 'princip compon analysi', 'pr', 'recognit']",.,"According to the shortcomings of long time and big errors about the moving plate recognition system, we present the moving plate recognition algorithm based on principal component analysis(PCA) color extraction. On the basis of the analysis of moving plate recognition system's basic principles, it introduces the basic principles and calculation steps about PCA extraction algorithm, and discusses the feasibility of applying the algorithm to PRS in the paper. The experimental results show that the algorithm has the advantages of faster speed and higher accuracy of recognition. The algorithm provides a new thought for the research on the moving plate recognition algorithm."
78,S0021961413004321.txt,"['copper-zinc alloy', 'phase equilibrium experi', 'excess configur entropi', 'excess entropi of mix', 'measur the low temperatur heat capac (5 to 300k) versu composit behaviour', 'chemic potenti data', 'thermodynam of copper-zinc alloy (brass)', 'solut calorimetri', 'subtract', 'reliabl data of the total excess entropi', 'neutron scatter investig', 'smmechmix=xasma+xbsmb', 'enthalp and chemic potenti data', 'excess enthalpi and excess entropi of mix', 'separ the entrop effect', 'vibrat and the configur part', 'experiment data', 'deliv experiment data', 'determin of the excess configur entropi', 'enthalp data', 'measur of the excess vibrat entropi', 'comput simul', 'brass', 'disord alloy']",.,"The thermodynamics of copper-zinc alloys (brass) was subject of numerous investigations. Brass is characterised by an excess enthalpy and excess entropy of mixing, both of which are negative. The enthalpic data were measured by solution calorimetry e.g., [1–3] and based on chemical potential data calculated from phase equilibrium experiments e.g., [4–6], the excess entropy of mixing could be evaluated e.g., [7–9]. This excess entropy contains both, the vibrational and the configurational parts. The excess vibrational entropy, defined as the deviation from the entropy of a mechanical mixture of the end members A and B (i.e., Smmechmix=XASmA+XBSmB), can be determined by measuring the low temperature heat capacity (5 to 300K) versus composition behaviour. The determination of the excess configurational entropy, i.e., the excess entropy coming from non-random atomic distributions and defects, is much more difficult. Here, neutron scattering investigations together with computer simulations are normally used. If, however, reliable data of the total excess entropy (from enthalpic and chemical potential data) are available, the measurement of the excess vibrational entropy enables the determination of the excess configurational entropy simply by subtraction. Since configurational and vibrational entropies may have different temperature dependencies, it is worthwhile to separate the entropic effects. This is one aim of this study. Another aim is to deliver experimental data so that first principles studies can test their models on a disordered alloy, whose structural details (short-range order) depend on temperature.
"
79,S0021999113005603.txt,"['resolv the veloc and shear-stress profil', 'cumul averag techniqu', 'mth order polynomi', 'new slip veloc', 'suppli highli fluctuat data to the macro solver', 'macro solver', 'stress tensor field', 'least-squar polynomi fit', 'cam', 'stabil issu', 'nth order polynomi', 'compress wall micro-el solut', 'shear-stress profil', 'polynomi', 'divid into spatially-ori bin', 'least-squar fit', 'cumul averag method', 'continu function', 'macro solut', 'irving–kirkwood relationship', 'reduc nois', 'veloc']",.,"After all micro elements reach a relaxed steady-state, measurements are obtained using a cumulative averaging technique to reduce noise. Each micro element is divided into spatially-oriented bins in the y-direction in order to resolve the velocity and shear-stress profiles. Velocity in each bin is measured using the Cumulative Averaging Method (CAM) [24], while the stress tensor field is measured using the Irving–Kirkwood relationship [25]. A least-squares polynomial fit to the data is performed, which helps reduce noise further. The fit produces a continuous function that avoids stability issues arising from supplying highly fluctuating data to the macro solver. A least-squares fit is applied to an Nth order polynomial for the velocity profile in the core region, and an Mth order polynomial for the velocity profile in the constrained region:(16)〈ui,core〉=∑k=1Nbk,iyi′(N−k),for 0⩽yi′⩽hcore, and(17)〈ui,cs〉=∑k=1Mck,iyi″(M−k),for 0⩽yi″⩽hcs, where bk,i and ck,i are the coefficients of the polynomials used in the core micro region and constrained region respectively. An estimate of the new slip velocity uB for input to the macro solution (6) is taken directly from the compressed wall micro-element solution (16), at yi′=0.
"
80,S0167931713005042.txt,"['oxygen', 'etch mask', 'argon ga', 'cvd', 'hydrogen silsesquioxan', 'scan electron micrograph', 'ultra-nanocrystallin diamond', 'uncd wafer', 'ebl', 'ebl and hsq develop', 'Al discharg layer', 'prevent e-beam deflect due to charg build-up on the surfac', 'circular pillar', 'nanofeatur stamp were then creat from the sampl', 'chemic vapour deposit', 'sever stamp were produc', 'vapour', 'neg tone electron sensit resist', 'hsq', 'uncd', 't', 'etch diamond nanopillar', 'convent electron beam lithographi', 'rca clean', 'ultrason solvent clean', 'rie']",.,"We used 2μm of ultra-nanocrystalline diamond (UNCD) grown by chemical vapour deposition (CVD) on a ∼520μm silicon carrier wafer from Advanced Diamond Technologies Ltd. Detailed information about the material and the stamp fabrication can be found in our earlier paper [16]. The UNCD wafer was scribed into 1×1cm2 samples and subjected to RCA cleaning (SC-1), followed by ultrasonic solvent cleaning. Nanofeature stamps were then created from the samples using conventional electron beam lithography (EBL) with negative tone electron sensitive resist, hydrogen silsesquioxane (HSQ). An Al discharge layer was required above the resist to prevent e-beam deflection due to charge build-up on the surface [17]. Several stamps were produced with this process and the pattern written varied in design but consisted of arrays of circular pillars. After EBL and HSQ development, the HSQ was used as an etch mask for RIE with a mixture of oxygen and argon gas. The etched diamond nanopillars were typically 225nm high. Fig. 1 displays a scanning electron micrograph of some typical stamp features.
"
81,S2212667812000949.txt,"['discuss and analyz the import of hip-push appli in walk race', 'hip-push', 'object analysi on the sports-biomechan factor', 'sport biomechan', 'data and essay', 'deep develop and train of walk race', 'theoret basi']",.,"By referring to many relevant data and essays, this paper aims at discussing and analyzing the importance of hip-push applied in walking race,based on the point of the view on sports biomechanics .With redard to the existing problems,the authors have made an objective analysis on the sports-biomechanics factors that can influence the race,hoping to provide a theoretical basis for the deep development and training of walking race."
82,S0167931713002438.txt,"['a-sio2 lead', 'non-defect continuum random network model', 'spontan trap', 'a-sio2', 'identifi defect centr', 'neutral paramagnet defect', 'si–o bond', 'trap', 'trap in the bulk and at surfac of silica', 'electron', 'si–o bond dissoci', 'silicon dangl bond', 'neg charg defect', 'deep electron trap', 'molecular model', 'bulk', 'electron trap centr', 'weaken', 'silica', 'non-bridg oxygen centr', 'surfac of a-sio2']",.,"There have been suggestions that electrons can be trapped in the bulk and at surfaces of silica [15] but new models of electron trapping centres started to appear only recently. It has been suggested by Bersuker et al., who used molecular models, that electrons can be trapped by Si–O bonds in a-SiO2 leading to their weakening and thus facilitating Si–O bond dissociation [16]. Further calculations by Camellone et al. have shown that electrons can spontaneously trap in non-defective continuum random network model of a-SiO2 [17]. Recent calculations have also demonstrated that the two dominant neutral paramagnetic defects at surfaces of a-SiO2, the non-bridging oxygen centre and the silicon dangling bond, are deep electron traps and can form the corresponding negatively charged defects [18]. However, these theoretical predictions have not yet been confirmed experimentally, emphasising the challenges for identifying defect centres.
"
83,S0377221716304258.txt,"['composit oper', 'kroneck oper', 'mmpp', 'state space explos', 'matrix geometr method', 'statist multiplex of sever mmpp', 'superposit oper', 'underli equat', 'fit method', 'mmpp and map', 'model real system', 'EM algorithm', 'numer evalu of queue model', 'statist descriptor', 'two-stat model', 'compos multipl small-siz mmpp or map', 'studi the approxim fit of larg m3pp', 'm3pp']",.,"Two-state models are often insufficient to fit complex traces, therefore we also study the approximate fitting of large M3PPs. In the single class setting, a known limitation of MMPPs is the inability to simultaneously fit many statistical descriptors due to the non-linearity of their underlying equations (Bodrog, Heindl, Horváth, & Telek, 2008; Heindl, Horváth, & Gross, 2006; Horváth & Telek, 2009). This has led to the definition of several approaches to fit complex traces by composing multiple small-sized MMPPs or MAPs using Kronecker operators (Andersen & Nielsen, 1998; Casale, Zhang, & Smirni, 2010; Horváth & Telek, 2002). These methods employ composition operators for moment fitting, offering a different trade-off between computational cost and fitting accuracy compared to fitting methods based on the EM algorithm (Breuer, 2002; Horváth & Okamura, 2013; Klemm, Lindemann, & Lohmann, 2003). In particular, the superposition operator allows one to describe a trace by the statistical multiplexing of several MMPPs, at the expense of an exponential growth of the number of states in the resulting process (Sriram & Whitt, 1986). This state space explosion is an obstacle for the application of MMPPs and MAPs to modeling real systems; for example it considerably slows down, or even renders infeasible, the numerical evaluation of queueing models by matrix geometric methods (Bini, Meini, Steffé, Pérez, & Houdt, 2012; Pérez, Velthoven, & Houdt, 2008).
"
84,S037026930301801X.txt,"['reaction mechan', 'neutron-rich Be isotop', 'neutron-remov', 'xhe+a−xh cluster structur', 'comprehens measur of the neutron-remov and cluster breakup', 'decay energi', 'breakup cross-sect', 'di-clust structur', 'valenc neutron', 'neutron rich isotop', 'nuclei', 'wavefunct of the ground state and the excit state', 'alpha-particl', 'first-chanc cluster breakup cross-sect', 'cluster breakup', 'domin structur mode', 'breakup process']",.,"The measurements presented here provide evidence for the existence of di-cluster structures in 10–12,14Be. Certainly, if the breakup process samples the overlap between the wavefunctions of the ground state and the excited states, the first-chance cluster breakup cross-sections, shown in Fig. 4(a), indicate that the xHe+A−xHe cluster structure does not decrease over the mass range A=10, 12 and 14. Given also that the decay energy threshold increases with mass number, the present data may even indicate a slight increase in clustering. The breakup cross-sections also appear to demonstrate that these nuclei possess a stronger structural overlap with an α–Xn–α configuration, although the reaction mechanics by which this final state is reached may be complex. That is to say that the dominant structural mode of the neutron rich isotopes may be identified with two alpha-particles plus valence neutrons. These comprehensive measurements of the neutron-removal and cluster breakup for the first time provide experimental data whereby the structure of the most neutron-rich Be isotopes can be modeled via their reactions.
"
85,S0370269304009268.txt,"['the search for the higg boson', '(lhc)', 'decay channel', 'sld', 'standard model', 'part of the mass rang favor by the lep result', 'higg decay', 'larg hadron collid', 'intermedi higg mass region', 'main higg product mechan', 'higg mass', 'SM', 'rare decay', 'particl', 'higg product mechan', 'higg boson', 'tevatron', 'put a firm lower bound on the higg mass', 'higg', 'qcd background', 'span all the higg mass region up to 1\xa0tev', 'compar the measur cross section with the SM result', 'put limit on the higg mass', 'mh>114\xa0gev', 'hadron collid', 'h→γγ', '114≲mh≲160\xa0gev', 'gluon fusion', 'access part of the mass rang favor by the lep result']",.,"One of the great successes of the experimental program carried out at LEP has been to put a firm lower bound on the Higgs mass, mH>114 GeV [1], and at the same time, together with the information coming from SLD, to give a strong indirect evidence that the Higgs boson, the still missing particle of the Standard Model (SM), should be relatively light with a high probability for its mass to be below 200 GeV. The search for the Higgs boson is one of the main objective of the Tevatron and the future Large Hadron Collider (LHC), that are supposed to span all the Higgs mass regions up to 1 TeV. At hadron colliders the main Higgs production mechanism is the gluon fusion [2], a process whose knowledge is fundamental in order to put limits on the Higgs mass or, in case the Higgs is discovered, to compare the measured cross section with the SM result. Concerning the Higgs decay channels, it is quite difficult for an hadron collider to access part of the mass range favored by the LEP results, the so-called intermediate Higgs mass region 114≲mH≲160 GeV, because of the large QCD background to the dominant modes. In this region the rare decay H→γγ is the most interesting alternative to the usual decay channels.
"
86,S0301010414003115.txt,"['lowest electron singlet', 'coupl cluster hierarchi', 'O', 'ano', 'ccsd', 'LR', 'oxygen', 'cc3', 'lr-ccsd', 'cc2', 'perturb correct method', 'cc-pvtz', 'transit moment', '6s5p4d3f1g', 'atom natur orbit', 'excit energi', 'abelian symmetri', 'correl respons method', 'cis(d)', 'manganes', 'optimis structur', 'ccsdr(3)', 'Mn', 'D2', 'excit state calcul', 'eom-ccsd method', 'linear respons', 'all-electron correl calcul', 'cc', 'b3lyp/aug-cc-pvtz']",.,"The optimised structure at the B3LYP/aug-cc-pVTZ level was then used to perform calculations of the lowest electronic singlet excited states with the coupled cluster linear response (LR) coupled cluster hierarchy CCS, CC2, CCSD and CC3, along with perturbative corrected methods CIS(D) and CCSDR(3). The correlated response methods were performed with an all-electron atomic natural orbital (ANO) basis set contracted to 6s5p4d3f1g on manganese, [47] together with the cc-pVTZ basis set on the oxygen atoms. The all-electron correlated calculations invoked a 13 orbital frozen core (O 1s, Mn 1s2s2p3s3p). Trial calculations correlating these orbitals only had a minor effect on excitation energies. For comparison the EOM-CCSD method with the cc-pVTZ basis on all atoms was tested to compare with LR-CCSD. These formally give exactly the same excitation energies, although the transition moments are more accurate for LR-CCSD. Abelian symmetry (D2) was used in all correlated excited state calculations.
"
87,S0021999113004555.txt,"['strang carryov scheme', 'time-step restrict', 'newton solver', 'ars(2', 'hevi solut', 'one iter of a newton solver', 'strang split', '2) scheme', 'rosenbrock solut', 'runge–kutta imex scheme', 'slow the vertic advect', '3', 'atmospher motion', 'wave propag', 'vertic advect']",.,"Three Runge–Kutta IMEX schemes were tested by Ullrich and Jablonowski [23] for the HEVI solution of the equations governing atmospheric motion. They tested the ARS(2,3,2) scheme of Ascher et al. [1] and also suggested the less computationally expensive but nearly as accurate Strang carryover scheme. This involves Strang splitting but the first implicit stage is cleverly re-used from the final implicit stage of the previous time-step and so there is only one implicit solution per time-step. Another novel approach taken by Ullrich and Jablonowski [23] is to use a Rosenbrock solution in order to treat all of the vertical terms implicitly rather than just the terms involved in wave propagation. A Rosenbrock solution is one iteration of a Newton solver. This circumvents the time-step restriction associated with vertical advection at the cost of slowing the vertical advection.
"
88,S1574119211001544.txt,"['forward mode', 'extend the physic region of movement', 'perform potenti', 'push-commun mode', 'physic space', 'node mobil', 'protocol', 'mobil model', 'geograph region', 'network', 'node', 'impos potenti restrict', 'forc similar node to move within specif defin area']",.,"As future work on the protocol, we would promote two items. Firstly, the two mobility models that we have considered in this work propose possible way to capture social context in the way nodes move in the physical space, yet still potentially allowing nodes to explore the geographical regions considered in its entirety. Further insights to the performance potential could be given through the assessment of the protocol with other mobilities that can extend the physical region of movement as well as impose potential restrictions on the nodes mobility, for example by forcing similar nodes to move within specifically defined areas. Secondly, the different forwarding modes introduced in Section  3.3 express different levels of cooperation across the network. The push-community mode, for example, is a form of interest-community selfishness and assumes reciprocation in the nodes’ behaviour. The vulnerability (resp. resilience) of the protocol to different instances of node misbehaviours is a research item worth exploring.
"
89,S2212667814000732.txt,"['retrospect assess of environment carri capac', 'synthet assess method base on cloud theori is appli', 'environment carri capac', 'guid the environment manag of reclam', 'synthet assess method', 'field data', 'obtain the histor develop situat of reclam domain', 'improv the manag level', 'environment manag of reclam', 'cloud theori', 'marin reclam']",.,"The retrospective assessment of environmental carrying capacity aims to obtain the historical development situation of reclamation domain, it's an essential tool for improving the managed level and guiding the environmental management of reclamation. In this paper, a synthetic assessment method based on cloud theory is applied to evaluate the single factor and multiple factors environmental carrying capacity in Caofeidian marine district, Tangshan Bay, China. With the field data of five assessment indexes in recent six years, the assessment results are obtained which show that the marine reclamation has a certain impact for the marine environment."
90,S0022311514008691.txt,"['W', 'oxid dispers strengthen', 'oxid particl', 'precipit', 'Ti', '9 and 14at.% Cr', 'structur and composit of the particl', 'steel', 'dispers of ultra-fin oxid particl throughout the matrix', 'consolid', 'Fe and impur', 'radiat', 'solid solut', 'od', 'reduc swell', 'y2o3', 'irradi', 'class of steel', 'ferrit alloy', 'non-od steel', 'nano-scal He bubbl', 'constitu element', 'nanostructur', '14ywt', 'improv radiat toler', 'balanc', 'oxid', 'mechan alloy', 'od steel', 'improv the mechan properti of the system', 'swell']",.,"The class of steels known as oxide dispersion strengthened (ODS) ferritic alloys (also known as nanostructured ferritic alloys) consist of a dispersion of ultra-fine oxide particles throughout the matrix. These oxide particles serve to improve the mechanical properties of the system, particularly at high temperatures, of the system through inhibiting dislocation motion and grain boundary sliding. In nuclear applications the oxide particles have been suggested to act as point defect sinks [10,11] to improve radiation tolerance, and as preferential sites for the formation of nano-scale He bubbles therefore reducing swelling compared to non-ODS steels [12–15]. The ability of the oxide particles to improve these properties depends on the structure and composition of the particles [10,11,16,17] and their stability under irradiation. Typical compositions of ODS steels include between 9 and 14at.% Cr for oxidation resistance (most commonly 14at.%); W for solid solution hardening; Y2O3 that is put into solid solution during the initial, mechanical alloying, process but then during consolidation at high temperatures forms precipitates; and Ti to inhibit significant growth of the oxide particles; the balance being made up of Fe and impurities [18]. For this reason these steels are often referred to as 14YWT, reflecting the constituent elements.
"
91,S0022311515002354.txt,"['pellet clad mechan interact', 'hydrid', 'pcmi', 'thermal expans', 'local hydrid growth', 'crack phenomenon', 'hydrogen', 'fuel pellet', 'hydrostat tensil stress raiser', 'zirconium', 'delay hydrid crack', 'dhc', 'fuel', 'hydrogen diffus', 'clad']",.,"Hydrides, once precipitated in zirconium, degrade the mechanical properties of a component, leading to reductions in tensile strength, ductility and fracture toughness [35–40]. These changes can ultimately compromise the integrity of cladding during normal operating life , accident conditions and fuel storage [13]. As well as the degradation of mechanical properties, the presence of hydrides can also affect phenomena like pellet cladding mechanical interaction (PCMI); or introduce mechanisms for failure, such as delayed hydride cracking (DHC). The former mechanism is the product of thermal expansion in fuel pellets introducing stresses into the cladding, which may then lead to the formation of cracks in areas made brittle by large hydride concentrations [13]. The latter mechanism, DHC, is a sub-critical, time dependent cracking phenomenon that requires long range hydrogen diffusion for repeated local hydride growth and fracture at a hydrostatic tensile stress raiser [5,41,42]. The process occurs over an extended period of time under a continuously applied load that is below the yield stress of the material [5,41,42].
"
92,S0003491615001505.txt,"['lattic model', 'pauli equat', 'object hop on a lattic instead of particl', 'dirac equat', 'motion of the particl', 'massless spin-1/2 particl', 'object', 'the creutz model', 'lattic', 'continuum space-tim', 'measur scenario', 'futur research', 'particl move in a space-tim continuum']",.,"The next important step might be the derivation of the Dirac equation. The Creutz model  [32] suggests that we should consider incorporating into the logical inference treatment, the additional knowledge that one has objects hopping on a lattice instead of particles moving in a space-time continuum. Recall that up to Section  2.4, the description of the measurement scenario, robustness etc. is explicitly discrete. In Section  2.4, the continuum limit was taken only because our aim was to derive the Pauli equation, which is formulated in continuum space-time. Of course, the description of the motion of the particle in Section  2.6 is entirely within a continuum description but there is no fundamental obstacle to replace this treatment by a proper treatment of objects hopping on a lattice. Therefore it seems plausible that the logical inference approach can be extended to describe massless spin-1/2 particles moving in continuum space-time by considering the continuum limit of the corresponding lattice model. An in-depth, general treatment of this problem is beyond the scope of the present paper and we therefore leave this interesting problem for future research.
"
93,S092702561300267X.txt,"['perform cast process simul with incorpor full diffusion-govern solidif kinet', 'multiphas volum averag solidif model', 'ternari alloy', 'thermodynam data', 'isat approach', 'solid', 'onlin call of thermodynam data', 'full diffusion-govern solidif kinet', 'current model', 'incorpor the thermodynam of ternari alloy and liquid diffusion-govern solidif kinet into a multiphas volum averag solidif model', 'extend to consid the back diffus into the solid', 'modif of the previou model use a linear phase diagram', 'liquid diffusion-govern solidif kinet', 'isat', 'discret volum element', 'tabul and interpol program', 'cast process simul', 'In situ adapt tabul', 'modif', 'back diffus']",.,"In previous publications the present authors proposed a method to incorporate the thermodynamics of ternary alloys and liquid diffusion-governed solidification kinetics into a multiphase volume average solidification model [23,24]. Back diffusion was disregarded. A way to access the thermodynamic data (e.g. Thermo-Calc [1]) through a tabulation and interpolation program ISAT (In Situ Adaptive Tabulation) was suggested. With the ISAT approach it is possible to perform an online call of the thermodynamic data and trace the formation of each individual solid phase (primary, peritectic, eutectic, etc.). As the number of calls of the thermodynamic data is equal to the product of the number of the discretized volume elements, the time steps and the calculation iterations per time step, the calculation becomes exhausting. Therefore, the current model is a modification of the previous model using a linearized phase diagram, and no online call of thermodynamic data is necessary. In addition, the model presented in this paper is extended to consider the back diffusion into the solid. With these modifications, the model can be used to perform casting process simulations with incorporated full diffusion-governed solidification kinetics for ternary alloys at a reasonable computation cost.
"
94,S0301010413004096.txt,"['neutron spectroscopi', 'adsorb H2 molecul', 'H2 adsorpt', 'mof', 'bind interact', 'liquid', 'static crystallograph studi', 'npd techniqu', '[al(oh)2o4] moieti', 'ga', 'characteris techniqu', 'H2', 'in', 'al-o⋯h2', 'D2', 'in situ inelast neutron scatter', 'weak interact', 'weak bind interact', 'permit direct observ of the dynam of the bind interact', 'nott-300', 'adsorb H2', 'adsorb ga molecul', 'organ ligand', 'mof complex', 'H2 bind interact', 'through-spac interact', 'aluminium-bas porou mof']",.,"It is critical to the success of the NPD technique that the MOF complex adsorbs a significant amount of D2 to boost the observed signal. This technique therefore has disadvantages when studying the binding interaction within MOFs with low uptakes. Furthermore, static crystallographic studies cannot provide insights into the dynamics of the adsorbed gas molecules. Thus, it is very challenging to probe experimentally the H2 binding interactions within a porous host system which has very low gas uptake due to the lack of suitable characterisation techniques. We report herein the application of the in situ inelastic neutron scattering (INS) technique to permit direct observation of the dynamics of the binding interactions between adsorbed H2 molecules and an aluminium-based porous MOF, NOTT-300, exhibiting moderate porosity, narrow pore window and very low uptake of H2. This neutron spectroscopy study reveals that adsorbed H2 molecules do not interact with the organic ligand within the pore channels, and form very weak interactions with [Al(OH)2O4] moieties via a type of through-spacing interaction (Al-O⋯H2). Interestingly, the very low H2 adsorption has been successfully characterised as weak binding interactions and, for the first time, we have found that the adsorbed H2 in the pore channel has a liquid type recoil motion at 5K (below its melting point) as a direct result of this weak interaction to the MOF host.
"
95,S0038092X15001681.txt,"['differ number of modul of the string are short-circuit', 'standard silicon system', 'revers current', '10 string of 18 modul per string', 'high effici system', 'vdc', 'voc of 873', '10 string of 24 modul per string', 'standard silicon modul', 'voc of 864', 'system', 'revers current analysi', 'high effici modul']",.,"For the reverse current analysis, for both scenarios (shading and short circuits) were tested on two systems, one system using standard silicon modules and another system using high efficiency modules. For the standard silicon system, a power of 50kWp was considered, with a system composed by 10 strings of 24 modules per string and an approximate system Voc of 864 [VDC]. For the high efficiency system, a power of 40kWp was considered, with a system composed by 10 strings of 18 modules per string and an approximate system Voc of 873 [VDC]. Fig. 5(a) shows the reverse current present in one string when different numbers of modules in the string are shaded by 90%. Fig. 5(b) shows the reverse current present in one string when different numbers of modules of the string are short-circuited. For both figures the continuous lines are for the standard silicon system and the dashed lines are for the high efficiency system.
"
96,S0393044012000198.txt,"['refer solut', 'vacuum radi spacetim', 'newman–penros constant', 'minkowski spacetim', 'maxwel field', 'weyl tensor', 'radi spacetim']",.,"RemarkThe purely radiative spacetimes used as reference solutions in our analysis are not perturbations of the Minkowski spacetime. A way of seeing this is to consider the Newman–Penrose constants of the spacetime. The Newman–Penrose constants are a set of absolutely conserved quantities defined as integrals of certain components of the Weyl tensor and the Maxwell fields over cuts of null infinity—see [19–21] for the Einstein–Maxwell case. In [22] it has been shown that the value of the Newman–Penrose constants for a vacuum radiative spacetime coincides with the value of the rescaled Weyl spinor at i+—this result can be extended to the electrovacuum case using the methods of this article. For the radiative spacetimes arising from the construction of [17] it can be seen that the value of the Weyl spinor at i+ is essentially the mass quadrupole of the seed static spacetime. It follows, that the Newman–Penrose constants of the radiative spacetime can take arbitrary values. On the other hand, for the Minkowski spacetime, the Newman–Penrose constants are exactly zero, and those of perturbations thereof will be small. Thus, in this precise sense, our radiative spacetimes are, generically, not perturbations of the Minkowski spacetime, unless all the Newman–Penrose constants vanish.
"
97,S2212667814000124.txt,"['cox', 'PX oxid', 'particl filter', 'tail ga', 'paramet estim', 'EM algorithm', 'PX', 'simul', 'soft sensor', 'data-driven nonlinear model', 'expectation-maxim algorithm']",.,"Based on expectation-maximization algorithm, parameter estimation was proposed for data-driven nonlinear models in this work. On this basis, particle filters were used to approximately calculate integrals, deriving EM algorithm based on particle filter. And the effectiveness of using the proposed algorithm for the soft sensor of COx content in tail gas of PX oxidation side reactions was verified through simulation results."
98,S0370269304007634.txt,"['electromagnet field', 'gravitipol', 'field theori of magnet monopol', 'graviton', 'gravit field', 'photon', 'non-abelian gaug theori', ""maxwell' equat of motion"", ""dirac' magnet monopol"", 'magnet monopol', ""einstein' post-newtonian equat of graviti"", 'electromagnet']",.,"I also could not resist mentioning another wild speculation [10]. Many years ago, inspired by the almost exact correspondence between Einstein's post-Newtonian equations of gravity and Maxwell's equations of motion I proposed the gravitipole in analogy with Dirac's magnetic monopole. After Dirac there was considerable debate on how a field theory of magnetic monopoles may be formulated. Eventually, 't Hooft and Polyakov showed that the magnetic monopole exists as an extended solution in certain non-abelian gauge theories. Most theorists now believe that electromagnetism is merely a piece of a grand unified theory and that magnetic monopoles exist. Might it not turn out that Einstein's theory is but a piece of a bigger theory and that gravitipoles exist? In grand unified theory the electromagnetic field is a component of a multiplet. Could it be that the gravitational field also somehow carries an internal index and that the field we observe is just a component of a multiplet? Throwing caution to the wind, I also asked in [10] if the gravitipole and the graviton might not form a representation under some dual group just as the magnetic monopole and the photon form a triplet under the dual group of Montonen and Olive [11].
"
99,S0378381215300674.txt,"['co2', 'saft-γ SW', 'fluid-phas equilibria', 'ϵch3', 'hydrophob molecul', 'alkylamin', 'mixtur of n-alkan and h2o', 'non-polar compound', 'mixtur of h2o', 'h2o', 'interact between h2o and the alkyl group', 'liquid', 'ch3 and ch2', 'ϵch2', 'descript of the alkane-rich phase', 'λch2', 'aqueou mixtur', 'fluid', 'vapour', 'alkyl group', 'λch3', 'pure-compon system']",.,"The next phase of our current study is to use the parameters obtained from pure-component systems in a transferable manner to represent the corresponding mixtures. Mixtures of n-alkanes and H2O have been studied previously with SAFT-γ SW [82]. In general it is well known that the extreme nature of the phase separation [150] makes it challenging to model mixtures of H2O with non-polar compounds. Because of the large differences in the dielectric constant of the two phases as well as in the dipole moment of H2O and the hydrophobic molecules, it especially difficult to obtain phase-independent unlike interaction parameters [112] and thus to model simultaneously the equilibrium phases. In previous work [82], emphasis was placed on obtaining an accurate description of the alkane-rich phases (both liquid and vapour), while small absolute (but not relative) deviations for the aqueous phase composition were achieved. The systems of interest in our current work are typically aqueous mixtures containing a high proportion of H2O, alkylamine, and CO2. Consequently, in order to provide an improved overall description of the fluid-phase equilibria at the conditions of interest, refinements have been made to the unlike parameters presented in the previous study [129] relating to the interactions between H2O and the alkyl groups, CH3 and CH2, namely ϵCH3,H2O, ϵCH2,H2O and λCH3,H2O, λCH2,H2O.
"
